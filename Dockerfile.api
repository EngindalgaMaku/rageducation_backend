# Multi-stage build for better caching - Dependencies Layer
FROM python:3.13-slim AS dependencies

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1

# System deps for marker-pdf and other dependencies
RUN apt-get update \
    && apt-get install -y --no-install-recommends \
      build-essential \
      curl \
      git \
      libgl1-mesa-dev \
      libglib2.0-0 \
      libsm6 \
      libxext6 \
      libxrender1 \
      libgomp1 \
      libgcc-s1 \
      ffmpeg \
      libfontconfig1 \
      libxml2-dev \
      libxslt-dev \
   && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Install Python deps - THIS LAYER WILL BE CACHED
COPY requirements.txt ./
RUN pip install --upgrade pip \
    && pip install -r requirements.txt

# Pre-cache Marker models during build - CRITICAL FOR PERFORMANCE
FROM dependencies AS model_cache

# Create model cache directory with proper permissions
RUN mkdir -p /app/models/marker_models && \
    chmod -R 755 /app/models

# CRITICAL: Set ALL cache environment variables BEFORE any Python imports
# These MUST be set at container level for marker library to detect them
ENV MARKER_CACHE_DIR=/app/models \
    TORCH_HOME=/app/models/torch \
    HUGGINGFACE_HUB_CACHE=/app/models/huggingface \
    TRANSFORMERS_CACHE=/app/models/transformers \
    HF_HOME=/app/models/hf_home \
    HF_DATASETS_CACHE=/app/models/datasets \
    PYTORCH_TRANSFORMERS_CACHE=/app/models/transformers \
    TRANSFORMERS_OFFLINE=1 \
    HF_HUB_OFFLINE=1 \
    MARKER_DISABLE_GEMINI=true \
    MARKER_USE_LOCAL_ONLY=true \
    MARKER_DISABLE_CLOUD_SERVICES=true \
    MARKER_DISABLE_ALL_LLM=true \
    MARKER_OCR_ONLY=true \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# Copy minimal source needed for model caching
COPY src/utils/model_cache_manager.py ./src/utils/
COPY src/__init__.py ./src/
COPY src/utils/__init__.py ./src/utils/

# CRITICAL FIX: Pre-download models directly using marker library
# This ensures models are actually cached in the Docker layer
RUN echo "üöÄ Pre-downloading Marker models during Docker build..." && \
    python -c "import os; os.environ.update({'TORCH_HOME': '/app/models/torch', 'HUGGINGFACE_HUB_CACHE': '/app/models/huggingface', 'TRANSFORMERS_CACHE': '/app/models/transformers', 'HF_HOME': '/app/models/hf_home'}); from marker.models import create_model_dict; models = create_model_dict(); print(f'‚úÖ Successfully pre-cached {len(models) if models else 0} model components!')" || \
    echo "‚ö†Ô∏è Direct model pre-caching failed, trying fallback..." && \
    python -c "import torch; torch.hub.set_dir('/app/models/torch'); print('‚úÖ Torch hub cache initialized')" || \
    echo "‚ö†Ô∏è Model pre-caching failed completely, models will download at runtime"

# Verify cache was actually created and show debugging info
RUN echo "üîç Cache verification:" && \
    ls -la /app/models/ || echo "‚ùå No /app/models directory" && \
    find /app/models -type f -name "*.bin" -o -name "*.safetensors" -o -name "*.pt" | head -10 || echo "‚ö†Ô∏è No model files found" && \
    du -sh /app/models/* 2>/dev/null || echo "‚ö†Ô∏è No cache subdirectories" && \
    echo "‚úÖ Cache verification complete"

# Runtime stage - Only rebuilds when source changes
FROM model_cache AS runtime

# Copy application source (this changes frequently)
COPY src ./src
RUN mkdir -p /app/data

# CRITICAL: Runtime environment variables MUST match build environment
# These ensure the cached models are found at runtime
ENV MARKER_CACHE_DIR=/app/models \
    TORCH_HOME=/app/models/torch \
    HUGGINGFACE_HUB_CACHE=/app/models/huggingface \
    TRANSFORMERS_CACHE=/app/models/transformers \
    HF_HOME=/app/models/hf_home \
    HF_DATASETS_CACHE=/app/models/datasets \
    PYTORCH_TRANSFORMERS_CACHE=/app/models/transformers \
    TRANSFORMERS_OFFLINE=1 \
    HF_HUB_OFFLINE=1 \
    MARKER_MAX_MEMORY_MB=3500 \
    MARKER_TIMEOUT_SECONDS=900 \
    MARKER_MAX_PAGES=200 \
    MARKER_ENABLE_RESOURCE_MONITORING=false \
    MARKER_DISABLE_GEMINI=true \
    MARKER_USE_LOCAL_ONLY=true \
    MARKER_DISABLE_CLOUD_SERVICES=true \
    MARKER_DISABLE_ALL_LLM=true \
    MARKER_OCR_ONLY=true

EXPOSE 8080

# Default command: run FastAPI with Cloud Run PORT support
CMD ["python", "src/api/main.py"]
