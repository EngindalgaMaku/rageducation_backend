# RAG3 Mikroservis Mimarisi Ã–nerisi

## Genel BakÄ±ÅŸ

Mevcut monolitik backend yapÄ±sÄ±nÄ± 4 ana mikroservise ayÄ±rarak daha modÃ¼ler, Ã¶lÃ§eklenebilir ve bakÄ±m yapÄ±labilir bir mimari Ã¶neriyoruz.

## Mikroservis BÃ¶lÃ¼mlemesi

### ğŸ”§ 1. PDF Processing Service (Marker TabanlÄ±)

**Port:** 8001  
**Sorumluluklar:**

- PDF dosyalarÄ±nÄ± yÃ¼ksek kaliteli Markdown'a dÃ¶nÃ¼ÅŸtÃ¼rme
- Marker kÃ¼tÃ¼phanesi entegrasyonu ve optimizasyonu
- BÃ¼yÃ¼k PDF'ler iÃ§in bellek yÃ¶netimi
- Model cache yÃ¶netimi (Marker modelleri iÃ§in)
- Fallback PDF iÅŸleme (PyPDF2)

**Ana Ã–zellikler:**

- Async PDF processing
- Memory-safe operations (4GB+ PDF desteÄŸi)
- Progress tracking
- Error recovery
- Cache-optimized model loading

---

### ğŸ¤– 2. Model Inference Service (Grok/Ollama)

**Port:** 8002  
**Sorumluluklar:**

- LLM model Ã§Ä±karÄ±mlarÄ± (Grok, Ollama)
- Cloud LLM client yÃ¶netimi
- Model selection ve switching
- Embedding generation
- Response generation

**Ana Ã–zellikler:**

- Multi-provider support (Groq, Ollama)
- Dynamic model switching
- Request queuing
- Timeout management
- Provider fallback mechanisms

---

### ğŸŒ 3. API Gateway Service

**Port:** 8000  
**Sorumluluklar:**

- Request routing ve koordinasyonu
- Session lifecycle yÃ¶netimi
- Authentication/Authorization
- Rate limiting
- API versioning
- Frontend ile iletiÅŸim

**Ana Ã–zellikler:**

- RESTful API endpoints
- Session-based operations
- Multi-format document upload
- Query handling
- Response aggregation

---

### ğŸ“„ 4. Document Processing Service

**Port:** 8003  
**Sorumluluklar:**

- Text chunking (semantic, markdown, hybrid)
- Vector embedding storage (FAISS + ChromaDB)
- Multi-backend vector search operations
- Document metadata yÃ¶netimi
- Persistent vector database yÃ¶netimi
- Cache yÃ¶netimi

**Ana Ã–zellikler:**

- Advanced chunking strategies
- Multi-backend vector similarity search (FAISS + ChromaDB)
- Persistent vector storage with ChromaDB
- Advanced metadata filtering and indexing
- Embedding cache
- Cross-backend search optimization
- Collection management and versioning

## Servis DetaylarÄ±

### 1. PDF Processing Service

#### Dahil Edilecek Dosyalar:

```
src/document_processing/
â”œâ”€â”€ enhanced_pdf_processor.py (1078+ satÄ±r) â­ ANA DOSYA
â”œâ”€â”€ pdf_processor.py (fallback)
â”œâ”€â”€ document_processor.py (dispatcher)
â”œâ”€â”€ docx_processor.py
â””â”€â”€ pptx_processor.py

src/utils/
â”œâ”€â”€ memory_manager.py â­ KRITIK
â”œâ”€â”€ model_cache_manager.py â­ KRITIK
â”œâ”€â”€ helpers.py
â””â”€â”€ logger.py
```

#### API Endpoints:

- `POST /convert/pdf-to-markdown`
- `GET /convert/status/{job_id}`
- `GET /health`
- `GET /models/status`

#### BaÄŸÄ±mlÄ±lÄ±klar:

- marker-pdf
- PyPDF2
- psutil (memory monitoring)
- threading/concurrent.futures

---

### 2. Model Inference Service

#### Dahil Edilecek Dosyalar:

```
src/utils/
â”œâ”€â”€ cloud_llm_client.py â­ ANA DOSYA
â”œâ”€â”€ model_selector.py â­ ANA DOSYA
â””â”€â”€ prompt_templates.py

src/embedding/
â””â”€â”€ embedding_generator.py â­ KRITIK

src/rag/
â”œâ”€â”€ rag_pipeline.py (generation kÄ±smÄ±)
â””â”€â”€ re_ranker.py

Ä°lgili config ve utility dosyalarÄ±
```

#### API Endpoints:

- `POST /models/generate`
- `POST /models/embed`
- `GET /models/available`
- `POST /models/select`
- `GET /health`

#### BaÄŸÄ±mlÄ±lÄ±klar:

- ollama (opsiyonel)
- requests (Groq API iÃ§in)
- sentence-transformers
- numpy

---

### 3. API Gateway Service

#### Dahil Edilecek Dosyalar:

```
src/api/
â”œâ”€â”€ main.py â­ ANA DOSYA (1177 satÄ±r)
â”œâ”€â”€ feedback_api.py
â””â”€â”€ main_minimal.py

src/
â”œâ”€â”€ api_server.py
â””â”€â”€ app_logic.py â­ KOORDINASYON

src/services/
â”œâ”€â”€ session_manager.py â­ KRITIK
â”œâ”€â”€ learning_loop_manager.py
â””â”€â”€ feedback_processor.py

src/config.py
```

#### API Endpoints:

- `GET /` (health check)
- `POST /sessions`
- `GET /sessions`
- `POST /documents/upload`
- `POST /rag/query`
- `POST /rag/configure-and-process`
- TÃ¼m frontend API endpoints

#### BaÄŸÄ±mlÄ±lÄ±klar:

- FastAPI
- SQLite (session management)
- Pydantic models

---

### 4. Document Processing Service

#### Dahil Edilecek Dosyalar:

```
src/text_processing/ (TÃœMÃœ)
â”œâ”€â”€ semantic_chunker.py â­ KRITIK
â”œâ”€â”€ text_chunker.py â­ KRITIK
â”œâ”€â”€ adaptive_chunk_refiner.py
â””â”€â”€ advanced_chunk_validator.py

src/vector_store/
â”œâ”€â”€ faiss_store.py â­ KRITIK
â”œâ”€â”€ chroma_store.py â­ KRITIK (YENÄ°)
â””â”€â”€ vector_store_manager.py â­ YENÄ° (Multi-backend)

src/embedding/
â””â”€â”€ embedding_generator.py (kopya/paylaÅŸÄ±mlÄ±)

src/utils/
â”œâ”€â”€ cache.py
â”œâ”€â”€ language_detector.py
â””â”€â”€ performance_monitor.py
```

#### API Endpoints:

- `POST /process/chunk`
- `POST /vector/store`
- `POST /vector/search`
- `GET /vector/stats`
- `POST /collections/create`
- `GET /collections/list`
- `DELETE /collections/{collection_name}`
- `GET /collections/{collection_name}/stats`
- `POST /vector/migrate` (FAISS â†” ChromaDB)
- `GET /health`

#### BaÄŸÄ±mlÄ±lÄ±klar:

- FAISS (hÄ±zlÄ± in-memory search)
- ChromaDB (persistent vector database)
- numpy
- sentence-transformers
- regex
- sqlite3 (ChromaDB backend)

---

### ğŸ—‚ï¸ 5. ChromaDB Vector Database Service

**Port:** 8004
**Sorumluluklar:**

- Persistent vector storage ve retrieval
- Collection management ve versioning
- Metadata filtering ve complex queries
- Backup ve restore operations
- Multi-tenant collection isolation
- Vector similarity search optimizations

**Ana Ã–zellikler:**

- HTTP API tabanlÄ± vector operations
- Scalable persistent storage
- Advanced metadata filtering
- Collection-based organization
- Built-in embedding functions
- REST API with OpenAPI documentation

#### API Endpoints:

- `POST /api/v1/collections`
- `GET /api/v1/collections`
- `POST /api/v1/collections/{collection_name}/add`
- `POST /api/v1/collections/{collection_name}/query`
- `GET /api/v1/collections/{collection_name}`
- `DELETE /api/v1/collections/{collection_name}`

#### BaÄŸÄ±mlÄ±lÄ±klar:

- ChromaDB server
- SQLite (metadata storage)
- Docker runtime
- HTTP client libraries

## Vector Storage Strategy

### Hybrid Approach: FAISS + ChromaDB

**FAISS (Fast Retrieval):**

- In-memory vector search (milisaniye response)
- BÃ¼yÃ¼k dataset'lerde ultra-hÄ±zlÄ± similarity search
- RAM-based operations
- Session bazlÄ± temporary storage

**ChromaDB (Persistent Storage):**

- KalÄ±cÄ± vector storage ve metadata
- Collection-based organization
- Advanced filtering capabilities
- Session ve document versioning
- Backup ve restore operations

### Storage Decision Logic:

```python
def choose_vector_backend(query_type, data_size, persistence_required):
    if persistence_required and data_size < 1M_vectors:
        return "chromadb"
    elif query_type == "realtime" and data_size < 100K_vectors:
        return "faiss"
    else:
        return "hybrid"  # FAISS for speed + ChromaDB for persistence
```

## Servisler ArasÄ± Ä°letiÅŸim

### Communication Patterns:

```mermaid
graph TB
    F[Frontend] --> AG[API Gateway :8000]

    AG --> PDF[PDF Processing :8001]
    AG --> MI[Model Inference :8002]
    AG --> DP[Document Processing :8003]

    PDF --> DP
    DP --> MI
    DP --> CDB[ChromaDB :8004]

    subgraph "Vector Storage Layer"
        DP -.-> FAISS[(FAISS Store)]
        DP -.-> VManager[(Vector Store Manager)]
        VManager --> CDB
        VManager --> FAISS
    end

    subgraph "Ä°Ã§ Servislerde"
        PDF -.-> Cache[(Model Cache)]
        CDB -.-> Storage[(Persistent Storage)]
        MI -.-> LLM[(LLM Models)]
    end
```

### Tipik Request Flow:

1. **Document Upload & Storage:**

   ```
   Frontend â†’ API Gateway â†’ PDF Processing â†’ Document Processing â†’
   Vector Store Manager â†’ [FAISS + ChromaDB] â†’ Persistent Storage
   ```

2. **RAG Query (Hybrid Search):**

   ```
   Frontend â†’ API Gateway â†’ Document Processing â†’ Vector Store Manager â†’
   [FAISS (fast) + ChromaDB (metadata filtering)] â†’ Model Inference â†’ Response
   ```

3. **Session Management:**

   ```
   Frontend â†’ API Gateway â†’ Session Manager â†’ Database + ChromaDB Collections
   ```

4. **Collection Management:**

   ```
   Frontend â†’ API Gateway â†’ Document Processing â†’ ChromaDB Service â†’
   Collection Operations (Create/List/Delete)
   ```

5. **Vector Migration (FAISS â†” ChromaDB):**
   ```
   Admin â†’ API Gateway â†’ Document Processing â†’ Vector Store Manager â†’
   [Export from Source] â†’ [Import to Target] â†’ Validation
   ```

## Deployment YapÄ±landÄ±rmasÄ±

### Docker Compose Ã–rneÄŸi:

```yaml
services:
  api-gateway:
    build: ./services/api-gateway
    ports:
      - "8000:8000"
    depends_on:
      - pdf-processing
      - model-inference
      - document-processing
      - chromadb

  pdf-processing:
    build: ./services/pdf-processing
    ports:
      - "8001:8001"
    volumes:
      - ./models:/app/models
      - ./cache:/app/cache

  model-inference:
    build: ./services/model-inference
    ports:
      - "8002:8002"
    environment:
      - GROQ_API_KEY=${GROQ_API_KEY}

  document-processing:
    build: ./services/document-processing
    ports:
      - "8003:8003"
    volumes:
      - ./data/vector_db:/app/vector_db
      - ./data/chromadb:/app/chromadb
    environment:
      - CHROMADB_HOST=chromadb
      - CHROMADB_PORT=8000
    depends_on:
      - chromadb

  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8004:8000"
    volumes:
      - ./data/chromadb:/chroma/chroma
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
```

## Avantajlar

### âœ… ModÃ¼lerlik

- Her servis baÄŸÄ±msÄ±z geliÅŸtirilebilir
- FarklÄ± teknolojiler/diller kullanÄ±labilir
- TakÄ±m Ã¼yeleri specialization yapabilir

### âœ… Ã–lÃ§eklenebilirlik

- PDF processing CPU-intensive â†’ Daha fazla kaynak
- Model inference GPU-intensive â†’ GPU instance'lar
- API Gateway load balancing â†’ Horizontal scaling

### âœ… Hataya DayanÄ±klÄ±lÄ±k

- Bir servis Ã§Ã¶kerse diÄŸerleri Ã§alÄ±ÅŸmaya devam eder
- Circuit breaker patterns
- Graceful degradation

### âœ… Deployment EsnekliÄŸi

- Servisler baÄŸÄ±msÄ±z deploy edilebilir
- Rolling updates
- A/B testing per service

## GeÃ§iÅŸ Stratejisi

### Faz 1: Servis AyÄ±rma

1. PDF Processing Service'i Ã§Ä±kar
2. Model Inference Service'i ayÄ±r
3. API Gateway'i refactor et
4. Document Processing Service'i oluÅŸtur

### Faz 2: Ä°letiÅŸim Kurma

1. HTTP REST API'leri tanÄ±mla
2. Error handling ve retry logic
3. Health checks ve monitoring

### Faz 3: Optimizasyon

1. Caching strategies
2. Connection pooling
3. Performance monitoring

## Teknisk Gereksinimler

### Shared Dependencies:

- Python 3.9+
- FastAPI
- Pydantic
- Docker & Docker Compose

### Service-Specific:

- **PDF Processing:** marker-pdf, PyPDF2, psutil
- **Model Inference:** ollama, groq, sentence-transformers
- **API Gateway:** SQLite, authentication libs
- **Document Processing:** FAISS, numpy, regex, ChromaDB client
- **ChromaDB Service:** ChromaDB server, Docker, SQLite backend

## ChromaDB Integration Benefits

### âœ… Persistent Vector Storage

- Veriler sistem yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda korunur
- Session ve document versioning
- Metadata ile complex filtering
- Collection-based organization

### âœ… Scalability & Performance

- BÃ¼yÃ¼k vector datasets iÃ§in optimized
- Built-in indexing ve caching
- HTTP API ile service separation
- Multi-tenant support

### âœ… Advanced Features

- Embedding functions support
- Metadata filtering ve search
- Backup ve restore capabilities
- OpenAPI documentation

### âœ… Development & Operations

- Docker-based deployment
- RESTful API interface
- Built-in monitoring ve logging
- Easy integration with existing services

## Migration Strategy

### Phase 1: ChromaDB Integration

1. ğŸ”„ ChromaDB service setup
2. ğŸ”„ Vector Store Manager implementation
3. ğŸ”„ FAISS + ChromaDB hybrid logic
4. ğŸ”„ Collection management APIs

### Phase 2: Data Migration

1. ğŸ”„ Existing FAISS data export
2. ğŸ”„ ChromaDB collection creation
3. ğŸ”„ Vector migration tools
4. ğŸ”„ Validation ve testing

### Phase 3: Production Deployment

1. ğŸ”„ Docker compose updates
2. ğŸ”„ Service coordination
3. ğŸ”„ Performance testing
4. ğŸ”„ Monitoring ve logging

## Sonraki AdÄ±mlar

1. âœ… Mimari tasarÄ±mÄ± onayÄ± (ChromaDB dahil)
2. ğŸ”„ ChromaDB service setup ve testing
3. ğŸ”„ Vector Store Manager implementation
4. ğŸ”„ Her servis iÃ§in ayrÄ± klasÃ¶r yapÄ±sÄ± oluÅŸturma
5. ğŸ”„ API interface tanÄ±mlarÄ± (ChromaDB endpoints dahil)
6. ğŸ”„ Docker configuration'larÄ± (ChromaDB service dahil)
7. ğŸ”„ Ä°lk servis (PDF Processing) ayÄ±rma
8. ğŸ”„ FAISS â†’ ChromaDB migration tools
9. ğŸ”„ Test ve integration (hybrid vector storage)

---

Bu mimari, kullanÄ±cÄ±nÄ±n belirttiÄŸi gereksinimleri karÅŸÄ±lar ve mevcut kodun bÃ¼yÃ¼k kÄ±smÄ±nÄ± koruyarak gÃ¼venli bir geÃ§iÅŸ saÄŸlar.

---

## Data Processing Pipeline ÅemasÄ±

### ğŸ“Š Genel Pipeline AkÄ±ÅŸÄ±

```mermaid
flowchart TD
    %% Input Layer
    UI[User Interface] --> AG[API Gateway :8000]

    %% Document Upload Pipeline
    AG --> |1. Document Upload| DU{Document Type?}
    DU --> |PDF| PDF[PDF Processing :8001]
    DU --> |DOCX/PPTX| DOC[Document Processing :8003]

    %% PDF Processing Pipeline
    PDF --> |2. Marker Conversion| MARK[Marker PDFâ†’MD]
    MARK --> |3. Memory Management| MEM[Memory Manager]
    MEM --> |4. Processed Markdown| DP[Document Processing :8003]

    %% Document Processing Pipeline
    DP --> |5. Text Analysis| CHUNK{Chunking Strategy}
    CHUNK --> |Semantic| SC[Semantic Chunker]
    CHUNK --> |Markdown| MC[Markdown Chunker]
    CHUNK --> |Hybrid| HC[Hybrid Chunker]

    SC --> EMBED[Embedding Generation]
    MC --> EMBED
    HC --> EMBED

    %% Vector Storage Pipeline
    EMBED --> |6. Vector Storage| VS{Storage Strategy}
    VS --> |Fast Access| FAISS[FAISS Store]
    VS --> |Persistent| CDB[ChromaDB :8004]
    VS --> |Hybrid| BOTH[FAISS + ChromaDB]

    %% Storage Persistence
    FAISS --> |Session Based| TEMP[(Temporary Storage)]
    CDB --> |Collections| PERSIST[(Persistent Storage)]
    BOTH --> TEMP
    BOTH --> PERSIST

    %% Query Pipeline
    AG --> |7. RAG Query| QP[Query Processing]
    QP --> |8. Vector Search| VSM[Vector Store Manager]
    VSM --> |9. Similarity Search| SEARCH{Search Strategy}

    SEARCH --> |Real-time| FAISS
    SEARCH --> |Complex Query| CDB
    SEARCH --> |Hybrid Search| BOTH

    %% Response Generation Pipeline
    SEARCH --> |10. Retrieved Context| MI[Model Inference :8002]
    MI --> |11. LLM Processing| LLM{Model Selection}
    LLM --> |Groq| GROQ[Groq API]
    LLM --> |Ollama| OLLAMA[Ollama Local]

    GROQ --> |12. Generated Response| AG
    OLLAMA --> |12. Generated Response| AG
    AG --> |13. Final Response| UI

    %% Background Processes
    DP -.-> |Session Management| SM[Session Manager]
    SM -.-> |Metadata| DB[(SQLite DB)]

    style PDF fill:#e1f5fe
    style DP fill:#f3e5f5
    style MI fill:#e8f5e8
    style CDB fill:#fff3e0
    style AG fill:#fce4ec
```

### ğŸ”„ Pipeline States ve Transitions

#### 1. Document Ingestion State Machine

```mermaid
stateDiagram-v2
    [*] --> Uploaded: Document Upload
    Uploaded --> ValidatingFormat: Format Check
    ValidatingFormat --> ProcessingPDF: PDF Detected
    ValidatingFormat --> ProcessingDOC: DOCX/PPTX Detected
    ValidatingFormat --> ErrorInvalidFormat: Unknown Format

    ProcessingPDF --> MarkerConversion: Marker Processing
    MarkerConversion --> MemoryOptimization: Large File Check
    MemoryOptimization --> ChunkingReady: Memory Managed
    MarkerConversion --> ChunkingReady: Small File

    ProcessingDOC --> ChunkingReady: Direct Processing

    ChunkingReady --> SemanticChunking: Strategy: Semantic
    ChunkingReady --> MarkdownChunking: Strategy: Markdown
    ChunkingReady --> HybridChunking: Strategy: Hybrid

    SemanticChunking --> EmbeddingGeneration
    MarkdownChunking --> EmbeddingGeneration
    HybridChunking --> EmbeddingGeneration

    EmbeddingGeneration --> VectorStorage: Embeddings Ready
    VectorStorage --> ProcessingComplete: Storage Success
    VectorStorage --> ErrorStorage: Storage Failed

    ProcessingComplete --> [*]
    ErrorInvalidFormat --> [*]
    ErrorStorage --> [*]
```

#### 2. Query Processing State Machine

```mermaid
stateDiagram-v2
    [*] --> QueryReceived: User Query
    QueryReceived --> QueryAnalysis: Analyze Intent
    QueryAnalysis --> VectorSearch: Search Strategy Selected

    VectorSearch --> FAISSSearch: Fast Retrieval Needed
    VectorSearch --> ChromaSearch: Complex Query
    VectorSearch --> HybridSearch: Optimal Strategy

    FAISSSearch --> ContextRetrieved: Results Found
    ChromaSearch --> ContextRetrieved: Results Found
    HybridSearch --> ContextRetrieved: Results Found

    VectorSearch --> NoResults: No Matches
    NoResults --> FallbackSearch: Try Alternative
    FallbackSearch --> ContextRetrieved: Fallback Success
    FallbackSearch --> EmptyResponse: No Context Available

    ContextRetrieved --> ModelInference: Context Ready
    ModelInference --> GroqProcessing: Groq Selected
    ModelInference --> OllamaProcessing: Ollama Selected

    GroqProcessing --> ResponseGenerated: Groq Response
    OllamaProcessing --> ResponseGenerated: Ollama Response
    ModelInference --> ModelError: Inference Failed

    ResponseGenerated --> [*]
    EmptyResponse --> [*]
    ModelError --> [*]
```

### ğŸ—ï¸ Service Communication Pipeline

#### Inter-Service Data Flow

```mermaid
sequenceDiagram
    participant U as User/Frontend
    participant AG as API Gateway
    participant PDF as PDF Service
    participant DP as Doc Processing
    participant VS as Vector Store Manager
    participant CDB as ChromaDB
    participant FAISS as FAISS Store
    participant MI as Model Inference

    %% Document Upload Flow
    U->>AG: POST /documents/upload
    AG->>PDF: POST /convert/pdf-to-markdown

    Note over PDF: Marker Processing<br/>Memory Management<br/>Cache Optimization

    PDF-->>AG: Processed Markdown
    AG->>DP: POST /process/chunk

    Note over DP: Chunking Strategy<br/>Text Analysis<br/>Embedding Generation

    DP->>VS: Vector Storage Request

    par Parallel Storage
        VS->>FAISS: Store in Memory
        VS->>CDB: POST /api/v1/collections/{id}/add
    end

    VS-->>DP: Storage Confirmation
    DP-->>AG: Processing Complete
    AG-->>U: Upload Success

    %% Query Processing Flow
    U->>AG: POST /rag/query
    AG->>DP: Query Analysis
    DP->>VS: Vector Search Request

    alt Fast Query
        VS->>FAISS: Similarity Search
    else Complex Query
        VS->>CDB: POST /api/v1/collections/{id}/query
    else Hybrid Search
        par
            VS->>FAISS: Memory Search
        and
            VS->>CDB: Persistent Search
        end
        Note over VS: Result Fusion & Ranking
    end

    VS-->>DP: Retrieved Context
    DP->>MI: Generate Response

    alt Groq Model
        MI->>MI: Groq API Call
    else Ollama Model
        MI->>MI: Local Model Inference
    end

    MI-->>DP: Generated Response
    DP-->>AG: Final Response
    AG-->>U: Query Result
```

### ğŸ“ˆ Pipeline Performance Metrics

#### Processing Stages Monitoring

```mermaid
gantt
    title RAG Pipeline Performance Timeline
    dateFormat X
    axisFormat %s

    section PDF Processing
    Document Upload    :milestone, upload, 0, 0
    Marker Conversion  :active, marker, after upload, 15s
    Memory Management  :memory, after marker, 3s

    section Text Processing
    Chunking Strategy  :chunk, after memory, 5s
    Embedding Gen     :embed, after chunk, 8s

    section Vector Storage
    FAISS Storage     :faiss, after embed, 2s
    ChromaDB Storage  :chroma, after embed, 4s
    Index Update      :index, after chroma, 3s

    section Query Processing
    Query Analysis    :milestone, query, after index, 0
    Vector Search     :search, after query, 1s
    Context Retrieval :retrieve, after search, 2s
    Model Inference   :inference, after retrieve, 5s
    Response Gen      :response, after inference, 3s

    section Total Timeline
    Complete Process  :milestone, complete, after response, 0
```

### ğŸ”§ Pipeline Configuration

#### Environment-Specific Pipeline Settings

```yaml
# pipeline-config.yml
pipeline:
  stages:
    pdf_processing:
      timeout: 300s
      memory_limit: 4GB
      cache_enabled: true
      fallback_enabled: true

    text_processing:
      chunking_strategy: "hybrid"
      chunk_size: 512
      chunk_overlap: 50
      embedding_model: "sentence-transformers/all-MiniLM-L6-v2"

    vector_storage:
      primary_backend: "chromadb"
      fallback_backend: "faiss"
      hybrid_threshold: 10000 # vectors
      collection_ttl: 7d

    model_inference:
      primary_provider: "groq"
      fallback_provider: "ollama"
      timeout: 30s
      max_retries: 3

  monitoring:
    metrics_enabled: true
    health_checks: true
    performance_tracking: true
    error_logging: true
```

### ğŸš¨ Pipeline Error Handling

#### Error Recovery Strategies

```mermaid
flowchart TD
    START([Pipeline Start]) --> PROCESS{Processing Stage}

    PROCESS --> |PDF Processing Error| PDF_ERROR[PDF Processing Failed]
    PROCESS --> |Embedding Error| EMB_ERROR[Embedding Failed]
    PROCESS --> |Storage Error| STORE_ERROR[Storage Failed]
    PROCESS --> |Inference Error| INF_ERROR[Model Inference Failed]

    PDF_ERROR --> PDF_FALLBACK{Fallback Available?}
    PDF_FALLBACK --> |Yes| PYPDF[PyPDF2 Fallback]
    PDF_FALLBACK --> |No| FAIL[Pipeline Failed]

    EMB_ERROR --> EMB_RETRY{Retry Count < 3?}
    EMB_RETRY --> |Yes| RETRY_EMB[Retry Embedding]
    EMB_RETRY --> |No| FAIL

    STORE_ERROR --> STORE_FALLBACK{Alternative Storage?}
    STORE_FALLBACK --> |ChromaDB â†’ FAISS| FAISS_STORE[Store in FAISS]
    STORE_FALLBACK --> |FAISS â†’ ChromaDB| CHROMA_STORE[Store in ChromaDB]
    STORE_FALLBACK --> |No Alternative| FAIL

    INF_ERROR --> INF_FALLBACK{Provider Fallback?}
    INF_FALLBACK --> |Groq â†’ Ollama| OLLAMA[Use Ollama]
    INF_FALLBACK --> |Ollama â†’ Groq| GROQ[Use Groq]
    INF_FALLBACK --> |No Provider| FAIL

    PYPDF --> SUCCESS[Pipeline Success]
    RETRY_EMB --> PROCESS
    FAISS_STORE --> SUCCESS
    CHROMA_STORE --> SUCCESS
    OLLAMA --> SUCCESS
    GROQ --> SUCCESS

    style SUCCESS fill:#c8e6c9
    style FAIL fill:#ffcdd2
```

Bu comprehensive pipeline ÅŸemasÄ±, mikroservis mimarisindeki tÃ¼m veri iÅŸleme akÄ±ÅŸlarÄ±nÄ±, state transitions'larÄ±, error handling stratejilerini ve performance monitoring'i detaylÄ± olarak gÃ¶stermektedir.
