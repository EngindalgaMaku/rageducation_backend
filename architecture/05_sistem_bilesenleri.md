# Sistem BileÅŸenleri ve Mimari Diyagramlar

## KiÅŸiselleÅŸtirilmiÅŸ Ders Notu ve Kaynak AsistanÄ±

### Genel Sistem Mimarisi

```mermaid
graph TB
    subgraph "KullanÄ±cÄ± KatmanÄ±"
        UI[Streamlit Web ArayÃ¼zÃ¼]
        API_DOC[API DokÃ¼mantasyonu]
    end

    subgraph "API KatmanÄ±"
        FastAPI[FastAPI Backend]
        AUTH[Authentication Middleware]
        RATE[Rate Limiting]
        CORS[CORS Handler]
    end

    subgraph "Ä°ÅŸ MantÄ±ÄŸÄ± KatmanÄ±"
        DOC_MGR[DokÃ¼man YÃ¶neticisi]
        QUERY_PROC[Sorgu Ä°ÅŸleyicisi]
        ANALYTICS[Analitik Motoru]
    end

    subgraph "RAG Ã‡ekirdeÄŸi"
        PROCESSOR[DokÃ¼man Ä°ÅŸleyicisi]
        CHUNKER[Metin ParÃ§alayÄ±cÄ±]
        EMBEDDER[Embedding Ãœreticisi]
        RETRIEVER[Bilgi Getirici]
        GENERATOR[YanÄ±t Ãœreticisi]
    end

    subgraph "Veri KatmanÄ±"
        VECTOR_DB[(VektÃ¶r VeritabanÄ± FAISS)]
        META_DB[(Metadata SQLite)]
        FILE_STORE[Dosya DepolamasÄ±]
        CACHE[Redis Cache]
    end

    subgraph "DÄ±ÅŸ Servisler"
        OPENAI[OpenAI API]
        HF[Hugging Face Models]
    end

    UI --> FastAPI
    FastAPI --> DOC_MGR
    FastAPI --> QUERY_PROC
    FastAPI --> ANALYTICS

    DOC_MGR --> PROCESSOR
    PROCESSOR --> CHUNKER
    CHUNKER --> EMBEDDER
    EMBEDDER --> VECTOR_DB

    QUERY_PROC --> RETRIEVER
    RETRIEVER --> VECTOR_DB
    RETRIEVER --> GENERATOR
    GENERATOR --> OPENAI

    EMBEDDER --> HF

    DOC_MGR --> FILE_STORE
    DOC_MGR --> META_DB
    ANALYTICS --> META_DB
    QUERY_PROC --> CACHE
```

### Veri AkÄ±ÅŸÄ± DiyagramÄ±

```mermaid
sequenceDiagram
    participant U as KullanÄ±cÄ±
    participant UI as Streamlit UI
    participant API as FastAPI
    participant DM as DokÃ¼man Manager
    participant RAG as RAG Ã‡ekirdeÄŸi
    participant VDB as VektÃ¶r DB
    participant LLM as OpenAI

    Note over U,LLM: DokÃ¼man YÃ¼kleme AkÄ±ÅŸÄ±
    U->>UI: DokÃ¼man YÃ¼kle
    UI->>API: POST /documents/upload
    API->>DM: process_document()
    DM->>RAG: extract_text()
    RAG->>RAG: chunk_text()
    RAG->>RAG: generate_embeddings()
    RAG->>VDB: store_vectors()
    VDB-->>DM: success
    DM-->>API: document_processed
    API-->>UI: upload_complete
    UI-->>U: BaÅŸarÄ±yla YÃ¼klendi

    Note over U,LLM: Soru-Cevap AkÄ±ÅŸÄ±
    U->>UI: Soru Sor
    UI->>API: POST /query
    API->>RAG: process_query()
    RAG->>VDB: similarity_search()
    VDB-->>RAG: relevant_chunks
    RAG->>LLM: generate_response()
    LLM-->>RAG: response_text
    RAG-->>API: final_response
    API-->>UI: response_data
    UI-->>U: YanÄ±t GÃ¶ster
```

## BileÅŸen Detay SpesifikasyonlarÄ±

### 1. API KatmanÄ± BileÅŸenleri

#### FastAPI Backend

```python
# EÄŸitim odaklÄ± API tasarÄ±mÄ±
class FastAPIApplication:
    """
    Ana API uygulamasÄ±
    EÄŸitim: Modern Python web framework Ã¶rneÄŸi
    """
    def __init__(self):
        self.app = FastAPI(
            title="Ders AsistanÄ± RAG API",
            description="EÄŸitim amaÃ§lÄ± RAG sistemi",
            version="1.0.0",
            docs_url="/docs",  # Swagger UI
            redoc_url="/redoc"  # ReDoc
        )
        self._setup_middleware()
        self._setup_routes()

    def _setup_middleware(self):
        # CORS iÃ§in
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["http://localhost:8501"],  # Streamlit
            allow_methods=["GET", "POST", "PUT", "DELETE"],
            allow_headers=["*"],
        )

        # Rate limiting (eÄŸitim amaÃ§lÄ±)
        @self.app.middleware("http")
        async def rate_limit_middleware(request: Request, call_next):
            # Basit rate limiting implementasyonu
            client_ip = request.client.host
            # ... rate limiting logic
            response = await call_next(request)
            return response
```

**Temel Endpoint'ler:**

- `POST /documents/upload` - DokÃ¼man yÃ¼kleme
- `GET /documents/` - DokÃ¼man listesi
- `DELETE /documents/{doc_id}` - DokÃ¼man silme
- `POST /query` - Soru sorma
- `GET /analytics/stats` - Sistem istatistikleri
- `GET /health` - Sistem durumu

#### Request/Response Modelleri

```python
# Pydantic modelleri (eÄŸitim amaÃ§lÄ± type safety)
class DocumentUploadRequest(BaseModel):
    """DokÃ¼man yÃ¼kleme isteÄŸi"""
    file_name: str
    file_content: bytes
    document_type: str = Field(..., description="pdf, docx, pptx")
    metadata: Optional[Dict[str, Any]] = None

class QueryRequest(BaseModel):
    """Sorgu isteÄŸi"""
    query: str = Field(..., min_length=3, max_length=500)
    max_results: int = Field(default=5, ge=1, le=10)
    include_sources: bool = Field(default=True)

class QueryResponse(BaseModel):
    """Sorgu yanÄ±tÄ±"""
    query: str
    response: str
    sources: List[SourceReference]
    processing_time_ms: int
    timestamp: datetime
```

### 2. RAG Ã‡ekirdek BileÅŸenleri

#### DokÃ¼man Ä°ÅŸleyici

```python
class DocumentProcessor:
    """
    EÄŸitim odaklÄ± dokÃ¼man iÅŸleme
    Desteklenen formatlar: PDF, DOCX, PPTX
    """

    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.text_extractors = {
            '.pdf': self._extract_from_pdf,
            '.docx': self._extract_from_docx,
            '.pptx': self._extract_from_pptx
        }

    async def process_document(self, file_path: str) -> ProcessedDocument:
        """
        Ana dokÃ¼man iÅŸleme fonksiyonu
        EÄŸitim: Async processing Ã¶rneÄŸi
        """
        start_time = time.time()

        # 1. Format tespiti
        file_format = Path(file_path).suffix.lower()
        if file_format not in self.text_extractors:
            raise UnsupportedFormatError(f"Format desteklenmiyor: {file_format}")

        # 2. Metin Ã§Ä±karma
        raw_text = await self._extract_text_async(file_path, file_format)

        # 3. Metin temizleme
        cleaned_text = self._clean_text(raw_text)

        # 4. Metin parÃ§alama
        chunks = self._chunk_text(cleaned_text)

        # 5. Metadata hazÄ±rlama
        document_metadata = self._create_metadata(file_path, len(chunks))

        processing_time = time.time() - start_time

        return ProcessedDocument(
            id=str(uuid.uuid4()),
            file_path=file_path,
            format=file_format,
            chunks=chunks,
            metadata=document_metadata,
            processing_time=processing_time
        )

# Veri yapÄ±larÄ± (eÄŸitim amaÃ§lÄ± clear structure)
@dataclass
class ProcessedDocument:
    id: str
    file_path: str
    format: str
    chunks: List[TextChunk]
    metadata: DocumentMetadata
    processing_time: float
```

#### Embedding Ãœreticisi

```python
class EmbeddingGenerator:
    """
    EÄŸitim odaklÄ± embedding Ã¼retimi
    Model deÄŸiÅŸtirilebilir tasarÄ±m
    """

    def __init__(self, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        self.model_name = model_name
        self.model = SentenceTransformer(model_name)
        self.embedding_cache = {}  # EÄŸitim: Basit caching Ã¶rneÄŸi

    def generate_embeddings(self, texts: List[str]) -> np.ndarray:
        """
        Batch embedding Ã¼retimi
        EÄŸitim: Efficient processing Ã¶rneÄŸi
        """
        # Cache kontrolÃ¼
        uncached_texts = []
        cached_embeddings = {}

        for i, text in enumerate(texts):
            text_hash = hashlib.md5(text.encode()).hexdigest()
            if text_hash in self.embedding_cache:
                cached_embeddings[i] = self.embedding_cache[text_hash]
            else:
                uncached_texts.append((i, text))

        # Yeni embedding'leri Ã¼ret
        if uncached_texts:
            batch_texts = [text for _, text in uncached_texts]
            batch_embeddings = self.model.encode(
                batch_texts,
                batch_size=32,
                show_progress_bar=True,
                convert_to_numpy=True,
                normalize_embeddings=True  # Cosine similarity iÃ§in
            )

            # Cache'e ekle
            for (index, text), embedding in zip(uncached_texts, batch_embeddings):
                text_hash = hashlib.md5(text.encode()).hexdigest()
                self.embedding_cache[text_hash] = embedding
                cached_embeddings[index] = embedding

        # SonuÃ§larÄ± sÄ±raya koy
        result_embeddings = np.array([cached_embeddings[i] for i in range(len(texts))])
        return result_embeddings
```

#### VektÃ¶r VeritabanÄ±

```python
class VectorDatabase:
    """
    EÄŸitim odaklÄ± vektÃ¶r veritabanÄ±
    FAISS kullanarak high-performance similarity search
    """

    def __init__(self, embedding_dim: int, index_type: str = "flat"):
        self.embedding_dim = embedding_dim
        self.index_type = index_type
        self.index = self._create_index()
        self.id_to_metadata: Dict[int, ChunkMetadata] = {}
        self.document_to_chunks: Dict[str, List[int]] = defaultdict(list)

    def _create_index(self) -> faiss.Index:
        """
        EÄŸitim: FarklÄ± FAISS index tÃ¼rleri
        """
        if self.index_type == "flat":
            # Exact search - eÄŸitim iÃ§in ideal
            return faiss.IndexFlatIP(self.embedding_dim)
        elif self.index_type == "ivf":
            # Approximate search - daha hÄ±zlÄ±
            quantizer = faiss.IndexFlatIP(self.embedding_dim)
            return faiss.IndexIVFFlat(quantizer, self.embedding_dim, 100)
        else:
            raise ValueError(f"Desteklenmeyen index tÃ¼rÃ¼: {self.index_type}")

    def add_document_chunks(self, document_id: str, chunks: List[TextChunk]):
        """
        DokÃ¼man chunk'larÄ±nÄ± ekle
        EÄŸitim: Batch insertion ve metadata management
        """
        embeddings = np.array([chunk.embedding for chunk in chunks])

        # Normalize embeddings for cosine similarity
        faiss.normalize_L2(embeddings)

        # Current index size
        current_size = self.index.ntotal

        # Add to FAISS index
        self.index.add(embeddings)

        # Add metadata
        for i, chunk in enumerate(chunks):
            chunk_index = current_size + i
            self.id_to_metadata[chunk_index] = ChunkMetadata(
                chunk_id=chunk.id,
                document_id=document_id,
                content=chunk.content,
                start_index=chunk.start_index,
                end_index=chunk.end_index,
                metadata=chunk.metadata
            )
            self.document_to_chunks[document_id].append(chunk_index)

        logger.info(f"Added {len(chunks)} chunks for document {document_id}")

    def search(self, query_embedding: np.ndarray, top_k: int = 5,
               filter_document: Optional[str] = None) -> List[SearchResult]:
        """
        Similarity search with optional filtering
        EÄŸitim: Advanced search features
        """
        # Normalize query
        query_embedding = query_embedding.reshape(1, -1)
        faiss.normalize_L2(query_embedding)

        # Search
        similarities, indices = self.index.search(query_embedding, top_k * 2)  # Over-fetch for filtering

        results = []
        for similarity, index in zip(similarities[0], indices[0]):
            if index == -1:  # FAISS padding
                continue

            chunk_metadata = self.id_to_metadata[index]

            # Document filtering
            if filter_document and chunk_metadata.document_id != filter_document:
                continue

            results.append(SearchResult(
                chunk_metadata=chunk_metadata,
                similarity_score=float(similarity),
                chunk_index=index
            ))

            if len(results) >= top_k:
                break

        return results
```

### 3. UI BileÅŸenleri

#### Streamlit Ana Uygulama

```python
class StreamlitApplication:
    """
    EÄŸitim odaklÄ± Streamlit uygulamasÄ±
    Modular component design
    """

    def __init__(self):
        self.api_client = APIClient("http://localhost:8000")
        self.setup_page_config()

    def setup_page_config(self):
        """Sayfa yapÄ±landÄ±rmasÄ±"""
        st.set_page_config(
            page_title="Ders AsistanÄ± RAG Sistemi",
            page_icon="ðŸ¤–",
            layout="wide",
            initial_sidebar_state="expanded"
        )

    def run(self):
        """Ana uygulama akÄ±ÅŸÄ±"""
        self.render_sidebar()

        # Tab-based navigation
        tab1, tab2, tab3, tab4 = st.tabs([
            "ðŸ¤” Soru Sor",
            "ðŸ“ DokÃ¼manlar",
            "ðŸ“Š Analitik",
            "ðŸ”§ Sistem"
        ])

        with tab1:
            self.render_query_interface()

        with tab2:
            self.render_document_management()

        with tab3:
            self.render_analytics_dashboard()

        with tab4:
            self.render_system_explanation()

    def render_query_interface(self):
        """
        Soru-cevap arayÃ¼zÃ¼
        EÄŸitim: Interactive query interface Ã¶rneÄŸi
        """
        st.header("ðŸ¤” Ders AsistanÄ±na Soru Sor")

        # Query input
        user_query = st.text_area(
            "Sorunuzu yazÄ±n:",
            placeholder="Ã–rnek: Machine Learning nedir?",
            height=100
        )

        col1, col2 = st.columns([1, 4])
        with col1:
            ask_button = st.button("ðŸš€ Sor", type="primary")
        with col2:
            show_sources = st.checkbox("Kaynak referanslarÄ±nÄ± gÃ¶ster", value=True)

        if ask_button and user_query:
            with st.spinner("Cevap hazÄ±rlanÄ±yor..."):
                response = self.api_client.query(user_query, include_sources=show_sources)

                if response:
                    # Response display
                    st.markdown("### ðŸ’¡ Cevap")
                    st.markdown(response.response)

                    # Sources
                    if show_sources and response.sources:
                        st.markdown("### ðŸ“š Kaynaklar")
                        for i, source in enumerate(response.sources, 1):
                            with st.expander(f"Kaynak {i}: {source.document_name}"):
                                st.write(f"**Sayfa/BÃ¶lÃ¼m:** {source.location}")
                                st.write(f"**Ä°Ã§erik:** {source.content[:200]}...")
                                st.write(f"**Benzerlik Skoru:** {source.similarity:.3f}")

                    # Metadata
                    with st.expander("ðŸ” Sorgu DetaylarÄ±"):
                        st.json({
                            "processing_time_ms": response.processing_time_ms,
                            "timestamp": response.timestamp.isoformat(),
                            "model_used": "gpt-3.5-turbo",
                            "chunks_retrieved": len(response.sources)
                        })
```

### 4. Analitik ve Ä°zleme BileÅŸenleri

#### Analytics Tracker

```python
class AnalyticsTracker:
    """
    EÄŸitim odaklÄ± analitik takip
    Simple but comprehensive metrics
    """

    def __init__(self, db_path: str = "analytics.db"):
        self.db_path = db_path
        self._init_database()

    def track_query(self, query_data: QueryAnalytics):
        """Sorgu analitiÄŸini kaydet"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO query_logs (
                    query_text, response_time_ms, chunks_retrieved,
                    query_type, user_session, timestamp
                ) VALUES (?, ?, ?, ?, ?, ?)
            """, (
                query_data.query_text,
                query_data.response_time_ms,
                query_data.chunks_retrieved,
                query_data.query_type,
                query_data.user_session,
                query_data.timestamp
            ))

    def get_usage_statistics(self) -> UsageStats:
        """KullanÄ±m istatistikleri"""
        with sqlite3.connect(self.db_path) as conn:
            # Toplam sorgu sayÄ±sÄ±
            total_queries = conn.execute(
                "SELECT COUNT(*) FROM query_logs"
            ).fetchone()[0]

            # Ortalama yanÄ±t sÃ¼resi
            avg_response_time = conn.execute(
                "SELECT AVG(response_time_ms) FROM query_logs"
            ).fetchone()[0]

            # En popÃ¼ler sorgu tipleri
            query_types = conn.execute("""
                SELECT query_type, COUNT(*)
                FROM query_logs
                GROUP BY query_type
                ORDER BY COUNT(*) DESC
            """).fetchall()

            return UsageStats(
                total_queries=total_queries,
                avg_response_time_ms=avg_response_time,
                query_type_distribution=dict(query_types)
            )
```

### 5. Performans ve Skalabilite Considerations

#### Caching Layer

```python
class CacheManager:
    """
    EÄŸitim odaklÄ± caching
    Redis-based with fallback to memory
    """

    def __init__(self, redis_url: Optional[str] = None):
        if redis_url:
            self.redis_client = redis.from_url(redis_url)
            self.use_redis = True
        else:
            self.memory_cache = {}
            self.use_redis = False

    def get_cached_embedding(self, text_hash: str) -> Optional[np.ndarray]:
        """Cached embedding getir"""
        if self.use_redis:
            cached = self.redis_client.get(f"embed:{text_hash}")
            if cached:
                return np.frombuffer(cached, dtype=np.float32)
        else:
            return self.memory_cache.get(f"embed:{text_hash}")

        return None

    def cache_embedding(self, text_hash: str, embedding: np.ndarray):
        """Embedding'i cache'le"""
        if self.use_redis:
            self.redis_client.setex(
                f"embed:{text_hash}",
                3600,  # 1 saat TTL
                embedding.tobytes()
            )
        else:
            self.memory_cache[f"embed:{text_hash}"] = embedding
```

### 6. GÃ¼venlik ve Hata YÃ¶netimi

#### Error Handling

```python
# EÄŸitim odaklÄ± error handling
class RAGSystemException(Exception):
    """Base exception for RAG system"""
    pass

class DocumentProcessingError(RAGSystemException):
    """Document processing failed"""
    pass

class EmbeddingGenerationError(RAGSystemException):
    """Embedding generation failed"""
    pass

class RetrievalError(RAGSystemException):
    """Information retrieval failed"""
    pass

# Global error handler
@app.exception_handler(RAGSystemException)
async def rag_exception_handler(request: Request, exc: RAGSystemException):
    return JSONResponse(
        status_code=500,
        content={
            "error": exc.__class__.__name__,
            "message": str(exc),
            "timestamp": datetime.now().isoformat()
        }
    )
```

Bu bileÅŸen spesifikasyonlarÄ± eÄŸitim odaklÄ± olarak tasarlanmÄ±ÅŸtÄ±r ve Ã¶ÄŸrencilerin sistem mimarisini kolayca anlayÄ±p geliÅŸtirmelerini saÄŸlar.
