#!/usr/bin/env python3
"""
GeliÅŸmiÅŸ Semantic Chunking Kalite Skorlama Sistemi Test DosyasÄ±

Bu test dosyasÄ± yeni geliÅŸtirilen geliÅŸmiÅŸ metrikleri test eder:

YENÄ° GELÄ°ÅMÄ°Å METRÄ°KLER:
âœ… Semantic Coherence Score (40%) - KonularÄ±n tutarlÄ±lÄ±ÄŸÄ±, topic modeling
âœ… Context Preservation Score (25%) - BaÄŸlam korunmasÄ±, referans Ã§Ã¶zÃ¼mÃ¼  
âœ… Information Completeness (20%) - Bilgi bÃ¼tÃ¼nlÃ¼ÄŸÃ¼, ana fikir tamamlanmasÄ±
âœ… Readability & Flow (15%) - DoÄŸal okuma akÄ±ÅŸÄ±, cÃ¼mle geÃ§iÅŸleri

ESKÄ° SORUNLU METRÄ°KLER (artÄ±k kullanÄ±lmÄ±yor):
âŒ Boyut Skoru (30%): 200-800 karakter optimal - Ã§ok basit
âŒ TutarlÄ±lÄ±k Skoru (30%): Tam cÃ¼mle sayÄ±sÄ± - anlamsal deÄŸil  
âŒ YapÄ± Skoru (20%): BaÅŸlÄ±k/liste bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ - yetersiz
âŒ Okunabilirlik (20%): Kelime/cÃ¼mle oranÄ± - anlamsÄ±z
"""

import sys
import os
import traceback
from typing import List, Dict

# Proje kÃ¶k dizinini sys.path'e ekle
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from src.text_processing.semantic_chunker import SemanticChunker
    from src.text_processing.advanced_chunk_validator import AdvancedChunkValidator
    print("âœ… GeliÅŸmiÅŸ semantic chunking modÃ¼lleri baÅŸarÄ±yla import edildi")
except ImportError as e:
    print(f"âŒ Import hatasÄ±: {e}")
    sys.exit(1)

# Test chunk Ã¶rnekleri - kalite skalasÄ± iÃ§in
TEST_CHUNKS = {
    "excellent_quality": """
# Yapay Zeka ve EÄŸitim Teknolojileri

Modern eÄŸitim sistemlerinde yapay zeka teknolojileri Ã¶nemli bir dÃ¶nÃ¼ÅŸÃ¼m yaratmaktadÄ±r. Bu teknolojiler, kiÅŸiselleÅŸtirilmiÅŸ Ã¶ÄŸrenme deneyimleri sunarak Ã¶ÄŸrenci baÅŸarÄ±sÄ±nÄ± artÄ±rmaya odaklanmaktadÄ±r.

KiÅŸiselleÅŸtirilmiÅŸ Ã¶ÄŸrenme sistemleri, her Ã¶ÄŸrencinin benzersiz Ã¶ÄŸrenme stilini ve hÄ±zÄ±nÄ± analiz ederek uygun iÃ§erik Ã¶nerileri sunar. Bu yaklaÅŸÄ±m, geleneksel tek boyutlu eÄŸitim yÃ¶ntemlerinden Ã§ok daha etkili sonuÃ§lar vermektedir.

AyrÄ±ca, yapay zeka destekli deÄŸerlendirme sistemleri Ã¶ÄŸrenci performansÄ±nÄ± gerÃ§ek zamanlÄ± olarak takip edebilmektedir. Bu sistemler, Ã¶ÄŸrencilerin gÃ¼Ã§lÃ¼ ve zayÄ±f yanlarÄ±nÄ± tespit ederek Ã¶ÄŸretmenlere deÄŸerli geri bildirimler saÄŸlar.
""".strip(),

    "good_quality": """
Makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n eÄŸitim alanÄ±ndaki uygulamalarÄ± giderek Ã§eÅŸitlenmektedir. Bu algoritmalar Ã¶zellikle bÃ¼yÃ¼k veri analizi ve Ã¶rÃ¼ntÃ¼ tanÄ±ma konularÄ±nda baÅŸarÄ±lÄ± olmaktadÄ±r.

EÄŸitim verilerinin analizi sayesinde Ã¶ÄŸrenci davranÄ±ÅŸlarÄ± hakkÄ±nda Ã¶nemli bilgiler elde edilebilir. Bu bilgiler doÄŸrultusunda eÄŸitim programlarÄ± optimize edilebilir ve daha etkili Ã¶ÄŸretim stratejileri geliÅŸtirilebilir.

SonuÃ§ olarak teknoloji ve eÄŸitimin entegrasyonu gelecekteki Ã¶ÄŸrenme deneyimlerini bÃ¼yÃ¼k Ã¶lÃ§Ã¼de ÅŸekillendirecektir.
""".strip(),

    "average_quality": """
Yapay zeka Ã§ok Ã¶nemli bir teknolojik geliÅŸme. Bu alanda birÃ§ok uygulama var. EÄŸitim sektÃ¶rÃ¼ bundan faydalanÄ±yor.

Ã–ÄŸrenciler iÃ§in faydalÄ± sistemler geliÅŸtirilmekte. Bunlar Ã¶ÄŸrenmeyi kolaylaÅŸtÄ±rÄ±yor. AyrÄ±ca Ã¶ÄŸretmenler de bu sistemleri kullanÄ±yor.

Gelecekte daha fazla geliÅŸme bekleniyor.
""".strip(),

    "poor_quality": """
Bu konu hakkÄ±nda detaylÄ± bilgi. Ancak ne hakkÄ±nda olduÄŸu net deÄŸil. 

Bunlar Ã¶nemli konular. Ã–zellikle ÅŸu nokta Ã§ok kritik. DiÄŸer konular da Ã¶yle.

Bu nedenle dikkat edilmeli. Ã‡Ã¼nkÃ¼ sonuÃ§larÄ± Ã§ok bÃ¼yÃ¼k.
""".strip(),

    "context_dependent": """
Bu sistemler daha Ã¶nce belirtilen avantajlarÄ± saÄŸlamaktadÄ±r. Onlar sayesinde eÄŸitim kalitesi artÄ±rÄ±labilir. BunlarÄ±n uygulanmasÄ± iÃ§in uygun altyapÄ± gereklidir.

AyrÄ±ca bu teknolojiler sÃ¼rekli geliÅŸmeye devam etmektedir. DolayÄ±sÄ±yla eÄŸitim kurumlarÄ±nÄ±n bu geliÅŸmeleri takip etmesi Ã¶nemlidir.
""".strip(),

    "incomplete_information": """
# Ã–nemli BaÅŸlÄ±k

Burada bir ÅŸeyler anlatÄ±lacak ama...

Ã–rneÄŸin:
- Ä°lk madde
- Ä°kinci madde baÅŸlÄ±yor ama
""".strip(),

    "excellent_flow": """
DoÄŸal dil iÅŸleme teknolojileri son yÄ±llarda bÃ¼yÃ¼k ilerleme kaydetmiÅŸtir. Bu geliÅŸmeler Ã¶zellikle transformer mimarisinin keÅŸfedilmesi ile hÄ±z kazanmÄ±ÅŸtÄ±r.

Buna baÄŸlÄ± olarak, dil modellerinin performansÄ± dramatik ÅŸekilde artmÄ±ÅŸtÄ±r. GPT ve BERT gibi modeller, Ã§eÅŸitli NLP gÃ¶revlerinde insan seviyesinde sonuÃ§lar elde etmeye baÅŸlamÄ±ÅŸtÄ±r.

SonuÃ§ olarak, bu teknolojik ilerlemeler eÄŸitim alanÄ±nda yeni fÄ±rsatlar yaratmaktadÄ±r. AkÄ±llÄ± ders asistanlarÄ± ve otomatik deÄŸerlendirme sistemleri bunun somut Ã¶rnekleridir.
""".strip(),

    "poor_flow": """
Teknoloji geliÅŸiyor. EÄŸitim Ã¶nemli. Yapay zeka var.

Sonra baÅŸka konular. Tabii ki bunlar da mÃ¼him. Ama diÄŸerleri farklÄ±.

BÃ¶ylece bu ÅŸekilde devam ediyor. Yani genel olarak durum bu.
""".strip()
}

def test_advanced_metrics_detailed():
    """GeliÅŸmiÅŸ metriklerin detaylÄ± analizi."""
    print("\nğŸ”¬ GELÄ°ÅMÄ°Å METRÄ°KLER DETAYYLI ANALÄ°Z")
    print("=" * 60)
    
    validator = AdvancedChunkValidator()
    
    for chunk_type, chunk_text in TEST_CHUNKS.items():
        print(f"\nğŸ“‹ {chunk_type.upper().replace('_', ' ')} ANALÄ°ZÄ°:")
        print("-" * 40)
        
        try:
            # GeliÅŸmiÅŸ analiz yap
            quality_score = validator.validate_chunk_quality(chunk_text)
            
            print(f"ğŸ“Š SKORLAR:")
            print(f"   ğŸ§  Semantic Coherence:     {quality_score.semantic_coherence:.3f} (40%)")
            print(f"   ğŸ”— Context Preservation:   {quality_score.context_preservation:.3f} (25%)")
            print(f"   âœ… Information Completeness: {quality_score.information_completeness:.3f} (20%)")
            print(f"   ğŸ“– Readability & Flow:     {quality_score.readability_flow:.3f} (15%)")
            print(f"   ğŸ¯ GENEL SKOR:            {quality_score.overall_score:.3f}")
            print(f"   {'âœ… GEÃ‡ERLÄ°' if quality_score.is_valid else 'âŒ GEÃ‡ERSÄ°Z'}")
            
            # DetaylÄ± analiz bilgileri
            analysis = quality_score.detailed_analysis
            print(f"\nğŸ“ˆ DETAYLAR:")
            print(f"   Uzunluk: {analysis.get('chunk_length', 0)} karakter")
            print(f"   CÃ¼mle sayÄ±sÄ±: {analysis.get('sentence_count', 0)}")
            print(f"   Kelime sayÄ±sÄ±: {analysis.get('word_count', 0)}")
            print(f"   Ortalama cÃ¼mle uzunluÄŸu: {analysis.get('avg_sentence_length', 0):.1f}")
            print(f"   Anahtar kelime sayÄ±sÄ±: {analysis.get('keyword_count', 0)}")
            print(f"   Referans sayÄ±sÄ±: {analysis.get('reference_count', 0)}")
            print(f"   GeÃ§iÅŸ kelimesi sayÄ±sÄ±: {analysis.get('transition_count', 0)}")
            
            # GÃ¼Ã§lÃ¼ yanlar
            if analysis.get('strengths'):
                print(f"   ğŸ’ª GÃ¼Ã§lÃ¼ yanlar: {', '.join(analysis['strengths'])}")
            
            # Sorun alanlarÄ±  
            if analysis.get('quality_issues'):
                print(f"   âš ï¸  Sorunlar: {', '.join(analysis['quality_issues'])}")
            
            print(f"   ğŸ“ Ä°lk 100 karakter: {chunk_text[:100]}...")
            
        except Exception as e:
            print(f"   âŒ Analiz hatasÄ±: {e}")

def test_context_aware_scoring():
    """BaÄŸlam farkÄ±ndalÄ±ÄŸÄ± testi."""
    print("\nğŸ”— BAÄLAM FARKINDA SKORLAMA TESTÄ°")
    print("=" * 50)
    
    validator = AdvancedChunkValidator()
    
    # BaÄŸlam serisi
    previous_chunk = """
Yapay zeka teknolojileri eÄŸitim sektÃ¶rÃ¼nde devrim yaratmaktadÄ±r. Bu teknolojiler kiÅŸiselleÅŸtirilmiÅŸ Ã¶ÄŸrenme deneyimleri sunarak her Ã¶ÄŸrencinin kendine Ã¶zgÃ¼ Ã¶ÄŸrenme stiline uygun iÃ§erik saÄŸlamaktadÄ±r.

Ã–zellikle makine Ã¶ÄŸrenmesi algoritmalarÄ±, Ã¶ÄŸrenci davranÄ±ÅŸlarÄ±nÄ± analiz ederek en uygun Ã¶ÄŸretim stratejilerini belirlemekte bÃ¼yÃ¼k rol oynamaktadÄ±r.
""".strip()
    
    test_chunk = TEST_CHUNKS["context_dependent"]
    
    next_chunk = """
Bu nedenle eÄŸitim kurumlarÄ±nÄ±n teknolojik altyapÄ±larÄ±nÄ± gÃ¼Ã§lendirmeleri ve Ã¶ÄŸretmenlerini bu konularda eÄŸitmeleri bÃ¼yÃ¼k Ã¶nem taÅŸÄ±maktadÄ±r.

Gelecekte yapay zeka destekli eÄŸitim sistemlerinin daha da yaygÄ±nlaÅŸmasÄ± ve eÄŸitim kalitesinin artÄ±rÄ±lmasÄ± beklenmektedir.
""".strip()
    
    print("ğŸ” TESTÄ° YAPILAN CHUNK:")
    print(f"   {test_chunk[:80]}...")
    
    # BaÄŸlam olmadan test
    print("\nğŸ“Š BAÄLAM OLMADAN:")
    score_no_context = validator.validate_chunk_quality(test_chunk)
    print(f"   Context Preservation Score: {score_no_context.context_preservation:.3f}")
    print(f"   Overall Score: {score_no_context.overall_score:.3f}")
    
    # BaÄŸlam ile test  
    print("\nğŸ“Š BAÄLAM Ä°LE:")
    score_with_context = validator.validate_chunk_quality(test_chunk, previous_chunk, next_chunk)
    print(f"   Context Preservation Score: {score_with_context.context_preservation:.3f}")
    print(f"   Overall Score: {score_with_context.overall_score:.3f}")
    
    # Fark analizi
    context_improvement = score_with_context.context_preservation - score_no_context.context_preservation
    overall_improvement = score_with_context.overall_score - score_no_context.overall_score
    
    print(f"\nğŸ“ˆ BAÄLAM ETKÄ°SÄ°:")
    print(f"   Context Score Ä°yileÅŸmesi: {context_improvement:+.3f}")
    print(f"   Overall Score Ä°yileÅŸmesi: {overall_improvement:+.3f}")
    print(f"   {'âœ… BaÄŸlam pozitif etki yaptÄ±' if overall_improvement > 0 else 'âš ï¸ BaÄŸlam negatif/nÃ¶tr etki'}")

def test_score_distribution():
    """Skor daÄŸÄ±lÄ±mÄ± ve eÅŸik analizi."""
    print("\nğŸ“Š SKOR DAÄILIMI VE KALITE EÅÄ°KLERÄ° ANALÄ°ZÄ°")
    print("=" * 60)
    
    validator = AdvancedChunkValidator()
    results = []
    
    for chunk_type, chunk_text in TEST_CHUNKS.items():
        score = validator.validate_chunk_quality(chunk_text)
        results.append({
            'type': chunk_type,
            'overall': score.overall_score,
            'coherence': score.semantic_coherence,
            'context': score.context_preservation,
            'completeness': score.information_completeness,
            'readability': score.readability_flow,
            'valid': score.is_valid
        })
    
    # Skor tablosu
    print("\nğŸ“‹ SKOR TABLOSU:")
    print(f"{'Chunk Type':<20} {'Overall':<8} {'Coherence':<9} {'Context':<8} {'Complete':<8} {'Readable':<8} {'Valid':<6}")
    print("-" * 78)
    
    for result in results:
        validity_icon = "âœ…" if result['valid'] else "âŒ"
        print(f"{result['type']:<20} {result['overall']:<8.3f} {result['coherence']:<9.3f} "
              f"{result['context']:<8.3f} {result['completeness']:<8.3f} "
              f"{result['readability']:<8.3f} {validity_icon:<6}")
    
    # Ä°statistikler
    valid_count = sum(1 for r in results if r['valid'])
    print(f"\nğŸ“ˆ Ä°STATÄ°STÄ°KLER:")
    print(f"   Toplam test: {len(results)}")
    print(f"   GeÃ§erli chunk: {valid_count}")
    print(f"   GeÃ§erlilik oranÄ±: {valid_count/len(results)*100:.1f}%")
    
    # En yÃ¼ksek ve en dÃ¼ÅŸÃ¼k skorlar
    max_score = max(results, key=lambda x: x['overall'])
    min_score = min(results, key=lambda x: x['overall'])
    
    print(f"   En yÃ¼ksek skor: {max_score['overall']:.3f} ({max_score['type']})")
    print(f"   En dÃ¼ÅŸÃ¼k skor: {min_score['overall']:.3f} ({min_score['type']})")
    print(f"   Skor aralÄ±ÄŸÄ±: {max_score['overall'] - min_score['overall']:.3f}")

def test_metric_weights():
    """Metrik aÄŸÄ±rlÄ±klarÄ±nÄ±n etkisini test et."""
    print("\nâš–ï¸  METRÄ°K AÄIRLIKLARININ ETKÄ° ANALÄ°ZÄ°")  
    print("=" * 50)
    
    validator = AdvancedChunkValidator()
    
    # Test chunk'Ä± seÃ§
    test_chunk = TEST_CHUNKS["excellent_quality"]
    score = validator.validate_chunk_quality(test_chunk)
    
    print("ğŸ§® AÄIRLIK HESAPLAMA Ã–RNEÄÄ°:")
    print(f"   Semantic Coherence:     {score.semantic_coherence:.3f} Ã— 40% = {score.semantic_coherence * 0.40:.3f}")
    print(f"   Context Preservation:   {score.context_preservation:.3f} Ã— 25% = {score.context_preservation * 0.25:.3f}")
    print(f"   Information Completeness: {score.information_completeness:.3f} Ã— 20% = {score.information_completeness * 0.20:.3f}")
    print(f"   Readability & Flow:     {score.readability_flow:.3f} Ã— 15% = {score.readability_flow * 0.15:.3f}")
    
    calculated_total = (score.semantic_coherence * 0.40 + 
                       score.context_preservation * 0.25 +
                       score.information_completeness * 0.20 + 
                       score.readability_flow * 0.15)
    
    print(f"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"   TOPLAM HESAPLANAN:      {calculated_total:.3f}")
    print(f"   SÄ°STEM SKORU:          {score.overall_score:.3f}")
    print(f"   FARK:                  {abs(calculated_total - score.overall_score):.3f}")
    
    # AÄŸÄ±rlÄ±k deÄŸiÅŸikliÄŸi simÃ¼lasyonu
    print(f"\nğŸ”„ AÄIRLIK DEÄÄ°ÅÄ°KLÄ°ÄÄ° SÄ°MÃœLASYONU:")
    
    # Coherence aÄŸÄ±rlÄ±ÄŸÄ±nÄ± artÄ±r
    alt_score_1 = (score.semantic_coherence * 0.60 + 
                   score.context_preservation * 0.20 +
                   score.information_completeness * 0.15 + 
                   score.readability_flow * 0.05)
    print(f"   Coherence AÄŸÄ±rlÄ±k 60%'a Ã§Ä±karsa: {alt_score_1:.3f}")
    
    # Context aÄŸÄ±rlÄ±ÄŸÄ±nÄ± artÄ±r
    alt_score_2 = (score.semantic_coherence * 0.20 + 
                   score.context_preservation * 0.50 +
                   score.information_completeness * 0.20 + 
                   score.readability_flow * 0.10)
    print(f"   Context AÄŸÄ±rlÄ±k 50%'e Ã§Ä±karsa:   {alt_score_2:.3f}")

def test_comparison_old_vs_new():
    """Eski ve yeni sistem karÅŸÄ±laÅŸtÄ±rmasÄ±."""
    print("\nâš¡ ESKÄ° VS YENÄ° SÄ°STEM KARÅILAÅTIRMASI")
    print("=" * 55)
    
    chunker = SemanticChunker()
    
    print("ğŸ” KARÅILAÅTIRMA Ã–RNEKLERÄ°:")
    
    for chunk_type, chunk_text in TEST_CHUNKS.items():
        print(f"\nğŸ“ {chunk_type.upper().replace('_', ' ')}:")
        print(f"   Ä°Ã§erik: {chunk_text[:60]}...")
        
        try:
            # Yeni sistem
            quality = chunker._validate_chunk_quality(chunk_text)
            
            print(f"   ğŸ†• YENÄ° SÄ°STEM:")
            print(f"      Overall Score: {quality.get('overall_score', 0):.3f}")
            print(f"      Coherence: {quality.get('coherence_score', 0):.3f} (gerÃ§ek anlamsal)")
            print(f"      Context: {quality.get('context_score', 0):.3f} (baÄŸlam korunmasÄ±)")
            print(f"      Structure: {quality.get('structure_score', 0):.3f} (bilgi tamamlanmasÄ±)")
            print(f"      Readability: {quality.get('readability_score', 0):.3f} (akÄ±ÅŸ kalitesi)")
            print(f"      Valid: {'âœ…' if quality['is_valid'] else 'âŒ'}")
            
            if quality.get('strengths'):
                print(f"      ğŸ’ª GÃ¼Ã§lÃ¼: {', '.join(quality['strengths'][:2])}")
            if quality.get('issues'):
                print(f"      âš ï¸  Sorun: {', '.join(quality['issues'][:2])}")
                
        except Exception as e:
            print(f"   âŒ Test hatasÄ±: {e}")

def test_realistic_scoring_scenarios():
    """GerÃ§ekÃ§i skorlama senaryolarÄ±."""
    print("\nğŸ¯ GERÃ‡EKÃ‡Ä° SKORLAMA SENARYOLARÄ°")
    print("=" * 45)
    
    realistic_scenarios = {
        "academic_paper_chunk": {
            "text": """
# Metodoloji

Bu Ã§alÄ±ÅŸmada karma yÃ¶ntem araÅŸtÄ±rmasÄ± benimsenmiÅŸtir. AraÅŸtÄ±rmanÄ±n nicel boyutunda 450 Ã¶ÄŸrenciye anket uygulanmÄ±ÅŸ, nitel boyutunda ise 15 Ã¶ÄŸretmenle derinlemesine gÃ¶rÃ¼ÅŸmeler gerÃ§ekleÅŸtirilmiÅŸtir.

Veri toplama sÃ¼reci Ã¼Ã§ aÅŸamada gerÃ§ekleÅŸmiÅŸtir. Ä°lk aÅŸamada pilot uygulama yapÄ±larak Ã¶lÃ§me aracÄ±nÄ±n geÃ§erlilik ve gÃ¼venilirliÄŸi test edilmiÅŸtir. Ä°kinci aÅŸamada ana uygulama gerÃ§ekleÅŸtirilmiÅŸ, Ã¼Ã§Ã¼ncÃ¼ aÅŸamada ise gÃ¶rÃ¼ÅŸmeler yapÄ±lmÄ±ÅŸtÄ±r.

Verilerin analizi SPSS 25 ve NVivo 12 programlarÄ± kullanÄ±larak gerÃ§ekleÅŸtirilmiÅŸtir. Nicel veriler iÃ§in betimsel istatistikler ve parametrik testler, nitel veriler iÃ§in ise tematik analiz uygulanmÄ±ÅŸtÄ±r.
""".strip(),
            "expected_range": (0.8, 0.95)
        },
        
        "technical_documentation": {
            "text": """
## API Endpoint: /users/{id}

Bu endpoint belirli bir kullanÄ±cÄ±nÄ±n bilgilerini getirir.

**Parametreler:**
- id (integer): KullanÄ±cÄ± ID'si
- format (string, optional): YanÄ±t formatÄ± (json, xml)

**YanÄ±t:**
```json
{
  "user_id": 123,
  "name": "John Doe",
  "email": "john@example.com"
}
```

**Hata KodlarÄ±:**
- 404: KullanÄ±cÄ± bulunamadÄ±
- 403: Yetkisiz eriÅŸim
""".strip(),
            "expected_range": (0.75, 0.90)
        },
        
        "fragmented_content": {
            "text": """
Bu konuda. Ancak diÄŸer ÅŸey.

Onlar. Bunlar da Ã¶yle. Yani bu ÅŸekilde.

DolayÄ±sÄ±yla. Ã‡Ã¼nkÃ¼ bahsettiÄŸimiz konular.
""".strip(),
            "expected_range": (0.2, 0.4)
        }
    }
    
    validator = AdvancedChunkValidator()
    
    for scenario_name, scenario_data in realistic_scenarios.items():
        text = scenario_data["text"]
        expected_min, expected_max = scenario_data["expected_range"]
        
        print(f"\nğŸ”¬ {scenario_name.upper().replace('_', ' ')} TESTÄ°:")
        
        score = validator.validate_chunk_quality(text)
        
        print(f"   ğŸ“Š Skor: {score.overall_score:.3f}")
        print(f"   ğŸ¯ Beklenen: {expected_min:.2f} - {expected_max:.2f}")
        
        # Skor aralÄ±k kontrolÃ¼
        in_range = expected_min <= score.overall_score <= expected_max
        print(f"   {'âœ… Beklenen aralÄ±kta' if in_range else 'âš ï¸ Beklenen aralÄ±k dÄ±ÅŸÄ±nda'}")
        
        # En dÃ¼ÅŸÃ¼k ve en yÃ¼ksek metrikler
        metrics = {
            'Coherence': score.semantic_coherence,
            'Context': score.context_preservation, 
            'Completeness': score.information_completeness,
            'Readability': score.readability_flow
        }
        
        highest = max(metrics, key=metrics.get)
        lowest = min(metrics, key=metrics.get)
        
        print(f"   ğŸ¥‡ En yÃ¼ksek: {highest} ({metrics[highest]:.3f})")
        print(f"   ğŸ¥‰ En dÃ¼ÅŸÃ¼k: {lowest} ({metrics[lowest]:.3f})")

def run_comprehensive_advanced_tests():
    """KapsamlÄ± geliÅŸmiÅŸ test sÃ¼iti."""
    print("ğŸš€ GELÄ°ÅMÄ°Å SEMANTÄ°K CHUNKING KALÄ°TE SKORLAMA SÄ°STEMÄ°")
    print("=" * 65)
    print("ğŸ“‹ Yeni Advanced Metrics ile GerÃ§ekÃ§i Kalite DeÄŸerlendirmesi")
    print("-" * 65)
    
    tests = [
        ("GeliÅŸmiÅŸ Metrikler DetaylÄ± Analiz", test_advanced_metrics_detailed),
        ("BaÄŸlam FarkÄ±nda Skorlama", test_context_aware_scoring),
        ("Skor DaÄŸÄ±lÄ±mÄ± ve EÅŸikler", test_score_distribution), 
        ("Metrik AÄŸÄ±rlÄ±klarÄ± Etkisi", test_metric_weights),
        ("Eski vs Yeni Sistem", test_comparison_old_vs_new),
        ("GerÃ§ekÃ§i Skorlama SenaryolarÄ±", test_realistic_scoring_scenarios),
    ]
    
    passed_tests = 0
    failed_tests = []
    
    for test_name, test_func in tests:
        try:
            print(f"\nâ–¶ï¸  {test_name} testi baÅŸlatÄ±lÄ±yor...")
            test_func()
            passed_tests += 1
            print(f"âœ… {test_name} testi BAÅARILI")
        except Exception as e:
            failed_tests.append(test_name)
            print(f"âŒ {test_name} testi HATA: {e}")
            traceback.print_exc()
    
    # SonuÃ§ raporu
    print("\n" + "=" * 65)
    print("ğŸ“Š TEST SONUÃ‡LARI - GELÄ°ÅMÄ°Å METRÄ°K SÄ°STEMÄ°")
    print("=" * 65)
    print(f"Toplam Test: {len(tests)}")
    print(f"BaÅŸarÄ±lÄ±: {passed_tests}")
    print(f"BaÅŸarÄ±sÄ±z: {len(failed_tests)}")
    print(f"BaÅŸarÄ± OranÄ±: {passed_tests/len(tests)*100:.1f}%")
    
    if failed_tests:
        print(f"\nBaÅŸarÄ±sÄ±z Testler:")
        for test in failed_tests:
            print(f"  - {test}")
    else:
        print("\nğŸ‰ TÃœM TESTLER BAÅARILI!")
        print("\nğŸ’¡ YENÄ° SÄ°STEM Ã–ZETÄ°:")
        print("   âœ… GerÃ§ek anlamsal tutarlÄ±lÄ±k analizi")
        print("   âœ… BaÄŸlam korunmasÄ± deÄŸerlendirmesi")  
        print("   âœ… Bilgi tamamlanmasÄ± kontrolÃ¼")
        print("   âœ… AkÄ±cÄ± okuma deneyimi Ã¶lÃ§Ã¼mÃ¼")
        print("   âœ… TÃ¼rkÃ§e dil yapÄ±sÄ±na Ã¶zel analiz")
        print("   âœ… BaÄŸlam farkÄ±nda skorlama")
        print("   âœ… GerÃ§ekÃ§i ve anlamlÄ± skorlar")
    
    return passed_tests == len(tests)

if __name__ == "__main__":
    try:
        # Ana test suitesi
        success = run_comprehensive_advanced_tests()
        
        # Ã‡Ä±kÄ±ÅŸ kodu
        exit_code = 0 if success else 1
        print(f"\nğŸ GeliÅŸmiÅŸ test sÃ¼reci tamamlandÄ± (Ã‡Ä±kÄ±ÅŸ kodu: {exit_code})")
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        print("\nâ›” Test sÃ¼reci kullanÄ±cÄ± tarafÄ±ndan durduruldu")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ Beklenmeyen hata: {e}")
        traceback.print_exc()
        sys.exit(1)