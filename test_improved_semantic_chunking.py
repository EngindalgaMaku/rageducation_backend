#!/usr/bin/env python3
"""
GeliÅŸmiÅŸ Semantic Chunking Sistemi Test DosyasÄ±

Bu dosya, yeni eklenen Ã¶zelliklerini test eder:
- Markdown baÅŸlÄ±k tespiti
- Liste tespiti (numaralÄ± ve madde iÅŸaretli)
- CÃ¼mle bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ korumasÄ±
- 200-800 karakter boyut optimizasyonu
- GeliÅŸmiÅŸ kalite kontrolÃ¼
"""

import sys
import os
import time
import traceback
from typing import List, Dict

# Proje kÃ¶k dizinini sys.path'e ekle
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from src.text_processing.semantic_chunker import SemanticChunker, create_semantic_chunks
    print("âœ… Semantic chunking modÃ¼lÃ¼ baÅŸarÄ±yla import edildi")
except ImportError as e:
    print(f"âŒ Import hatasÄ±: {e}")
    sys.exit(1)

# Test verileri
TEST_TEXTS = {
    "academic_turkish": """
# Yapay Zeka ve DoÄŸal Dil Ä°ÅŸleme AraÅŸtÄ±rmasÄ±

## GiriÅŸ

Yapay zeka alanÄ±nda doÄŸal dil iÅŸleme (NLP), makinelerin insan dilini anlayÄ±p iÅŸleyebilmesi iÃ§in geliÅŸtirilen teknolojilerin bÃ¼tÃ¼nÃ¼dÃ¼r. Bu Ã§alÄ±ÅŸmada, modern NLP yaklaÅŸÄ±mlarÄ±nÄ±n etkinliÄŸi araÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.

Son yÄ±llarda transformer mimarisinin geliÅŸtirilmesi ile birlikte, dil modellerinin performansÄ± Ã¶nemli Ã¶lÃ§Ã¼de artmÄ±ÅŸtÄ±r. GPT, BERT ve benzeri modeller, Ã§eÅŸitli NLP gÃ¶revlerinde insan dÃ¼zeyinde performans gÃ¶stermektedir.

## Metodoloji

AraÅŸtÄ±rmamÄ±zda kullanÄ±lan metodoloji ÅŸu adÄ±mlarÄ± iÃ§ermektedir:

1. **Veri Toplama**: TÃ¼rkÃ§e ve Ä°ngilizce akademik metinler derlenmiÅŸtir
2. **Ã–n Ä°ÅŸleme**: Metinler temizlenmiÅŸ ve normalize edilmiÅŸtir
3. **Model EÄŸitimi**: Transformer tabanlÄ± modeller eÄŸitilmiÅŸtir
4. **DeÄŸerlendirme**: Ã‡eÅŸitli metriklerle performans Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r

### Veri Seti Ã–zellikleri

KullanÄ±lan veri setinin Ã¶zellikleri ÅŸunlardÄ±r:

- Toplam dokÃ¼man sayÄ±sÄ±: 10,000
- Ortalama dokÃ¼man uzunluÄŸu: 2,500 kelime
- Dil daÄŸÄ±lÄ±mÄ±: %60 TÃ¼rkÃ§e, %40 Ä°ngilizce
- Konu alanlarÄ±: Teknoloji, tÄ±p, eÄŸitim, sosyal bilimler

## SonuÃ§lar

Deneysel Ã§alÄ±ÅŸmalar sonucunda elde edilen bulgular ÅŸu ÅŸekildedir:

### Performans Metrikleri

Model performansÄ± aÅŸaÄŸÄ±daki metriklerle deÄŸerlendirilmiÅŸtir:
- F1 Skoru: 0.92
- Hassasiyet (Precision): 0.89
- DuyarlÄ±lÄ±k (Recall): 0.95

Bu sonuÃ§lar, Ã¶nerilen yaklaÅŸÄ±mÄ±n etkinliÄŸini gÃ¶stermektedir.

## TartÄ±ÅŸma ve Gelecek Ã‡alÄ±ÅŸmalar

Elde edilen sonuÃ§lar literatÃ¼rdeki benzer Ã§alÄ±ÅŸmalarla karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, Ã¶nerilen yÃ¶ntemin rekabetÃ§i performans gÃ¶sterdiÄŸi gÃ¶rÃ¼lmektedir. Gelecek Ã§alÄ±ÅŸmalarda, daha bÃ¼yÃ¼k veri setleri Ã¼zerinde denemeler yapÄ±lmasÄ± planlanmaktadÄ±r.
""",
    
    "markdown_lists": """
# Proje YÃ¶netim Rehberi

## Proje BaÅŸlatma

Yeni bir proje baÅŸlatÄ±rken dikkat edilmesi gereken temel adÄ±mlar:

1. **Proje TanÄ±mÄ±**
   - AmaÃ§ ve hedefleri belirleme
   - Kapsam sÄ±nÄ±rlarÄ±nÄ± Ã§izme
   - BaÅŸarÄ± kriterlerini tanÄ±mlama

2. **Kaynak PlanlamasÄ±**
   - Ä°nsan kaynaÄŸÄ± ihtiyacÄ±
   - BÃ¼tÃ§e tahsisi
   - Zaman planlamasÄ±

3. **Risk Analizi**
   - Potansiyel riskleri belirleme
   - Risk Ã¶nleme stratejileri
   - Acil durum planlarÄ±

## TakÄ±m Organizasyonu

### Roller ve Sorumluluklar

Her takÄ±m Ã¼yesinin sorumluluklarÄ±nÄ±n net olarak tanÄ±mlanmasÄ± gerekir:

- **Proje YÃ¶neticisi**
  - Genel koordinasyon
  - Ä°letiÅŸim yÃ¶netimi
  - Ä°lerleme takibi

- **Teknik Lider**
  - Mimari kararlar
  - Kod kalitesi
  - Teknik mentÃ¶rlÃ¼k

- **GeliÅŸtirici**
  - Kod yazÄ±mÄ±
  - Test yazÄ±mÄ±
  - DokÃ¼mantasyon

### Ä°letiÅŸim Protokolleri

Etkili iletiÅŸim iÃ§in kurallara uyulmasÄ± Ã¶nemlidir:

* GÃ¼nlÃ¼k stand-up toplantÄ±larÄ±
* HaftalÄ±k ilerleme raporlarÄ±
* AylÄ±k deÄŸerlendirme toplantÄ±larÄ±
* Acil durumlar iÃ§in iletiÅŸim kanallarÄ±

## Kalite Kontrol

### Test Stratejileri

YazÄ±lÄ±m kalitesini saÄŸlamak iÃ§in:

1. Birim testleri (Unit Tests)
2. Entegrasyon testleri
3. KullanÄ±cÄ± kabul testleri
4. Performans testleri

### Kod Ä°ncelemesi

- Her commit iÃ§in kod incelemesi zorunludur
- En az bir kiÅŸi tarafÄ±ndan onaylanmalÄ±dÄ±r
- Standartlara uygunluk kontrol edilmelidir
""",

    "technical_content": """
# API DokÃ¼mantasyonu

## Kimlik DoÄŸrulama

API'ye eriÅŸim iÃ§in kimlik doÄŸrulama gereklidir. Ä°ki farklÄ± yÃ¶ntem desteklenir:

### API AnahtarÄ± ile Kimlik DoÄŸrulama

```python
import requests

headers = {
    'Authorization': 'Bearer YOUR_API_KEY',
    'Content-Type': 'application/json'
}

response = requests.get('https://api.example.com/data', headers=headers)
```

### OAuth 2.0 ile Kimlik DoÄŸrulama

OAuth 2.0 akÄ±ÅŸÄ±nÄ± kullanarak token alabilirsiniz:

```python
# Token alma
auth_data = {
    'client_id': 'your_client_id',
    'client_secret': 'your_client_secret',
    'grant_type': 'client_credentials'
}

token_response = requests.post('https://api.example.com/oauth/token', data=auth_data)
access_token = token_response.json()['access_token']
```

## Endpoint DetaylarÄ±

### KullanÄ±cÄ± Bilgileri

**GET /api/v1/users/{user_id}**

Belirli bir kullanÄ±cÄ±nÄ±n bilgilerini getirir.

**Parametreler:**
- `user_id` (integer): KullanÄ±cÄ± ID'si
- `include` (string, opsiyonel): Ä°Ã§erilecek iliÅŸkili veriler

**YanÄ±t Ã–rneÄŸi:**
```json
{
  "id": 123,
  "name": "Ali Veli",
  "email": "ali@example.com",
  "created_at": "2023-01-15T10:30:00Z"
}
```

### Veri OluÅŸturma

**POST /api/v1/data**

Yeni veri kaydÄ± oluÅŸturur.

```python
data = {
    'title': 'Yeni KayÄ±t',
    'content': 'KayÄ±t iÃ§eriÄŸi burada...',
    'tags': ['python', 'api', 'json']
}

response = requests.post('https://api.example.com/api/v1/data', 
                        json=data, headers=headers)
```
"""
}

def test_basic_functionality():
    """Temel chunking fonksiyonalitesini test et."""
    print("\nğŸ§ª TEMEL FONKSÄ°YONALÄ°TE TESTÄ°")
    print("=" * 50)
    
    # Basit metin ile test
    simple_text = "Bu basit bir test metnidir. Ä°kinci cÃ¼mle burada. ÃœÃ§Ã¼ncÃ¼ cÃ¼mle de eklenmiÅŸ."
    
    try:
        chunks = create_semantic_chunks(simple_text, target_size=100, language="tr")
        print(f"âœ… Basit metin chunking baÅŸarÄ±lÄ±: {len(chunks)} chunk oluÅŸturuldu")
        for i, chunk in enumerate(chunks):
            print(f"   Chunk {i+1}: {len(chunk)} karakter")
        return True
    except Exception as e:
        print(f"âŒ Basit metin chunking hatasÄ±: {e}")
        traceback.print_exc()
        return False

def test_markdown_structure():
    """Markdown yapÄ±sÄ± tespiti testleri."""
    print("\nğŸ§ª MARKDOWN YAPI TESPÄ°TÄ°")
    print("=" * 50)
    
    chunker = SemanticChunker()
    
    try:
        # Markdown yapÄ±sÄ±nÄ± tespit et
        structure = chunker._detect_text_structure(TEST_TEXTS["markdown_lists"])
        
        print(f"âœ… YapÄ±sal tespit baÅŸarÄ±lÄ±:")
        print(f"   - BaÅŸlÄ±k sayÄ±sÄ±: {len(structure['headers'])}")
        print(f"   - NumaralÄ± liste Ã¶ÄŸesi: {len(structure['numbered_lists'])}")
        print(f"   - Madde iÅŸaretli liste: {len(structure['bullet_lists'])}")
        print(f"   - Kod bloÄŸu: {len(structure['code_blocks'])}")
        
        # BaÅŸlÄ±klarÄ± kontrol et
        for header in structure['headers']:
            print(f"   H{header['level']}: {header['title']}")
        
        return True
    except Exception as e:
        print(f"âŒ Markdown yapÄ± tespiti hatasÄ±: {e}")
        traceback.print_exc()
        return False

def test_sentence_integrity():
    """CÃ¼mle bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ korumasÄ± testi."""
    print("\nğŸ§ª CÃœMLE BÃœTÃœNLÃœÄÃœ KORUMA")
    print("=" * 50)
    
    chunker = SemanticChunker()
    
    try:
        test_text = """Bu uzun bir test cÃ¼mlesidir ve kesilmemesi gerekir. Ä°kinci cÃ¼mle daha kÄ±sa. ÃœÃ§Ã¼ncÃ¼ cÃ¼mle orta uzunlukta bir cÃ¼mledir. DÃ¶rdÃ¼ncÃ¼ cÃ¼mle de test iÃ§in yazÄ±lmÄ±ÅŸtÄ±r."""
        
        # CÃ¼mle bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ koru
        preserved = chunker._preserve_sentence_integrity(test_text, 80)
        
        # CÃ¼mlelerin kesik olmadÄ±ÄŸÄ±nÄ± kontrol et
        if preserved.endswith('.') or preserved.endswith('!') or preserved.endswith('?'):
            print(f"âœ… CÃ¼mle bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ korundu ({len(preserved)} karakter)")
            print(f"   SonuÃ§: {preserved}")
            return True
        else:
            print(f"âŒ CÃ¼mle bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ bozuldu: {preserved[-20:]}")
            return False
    except Exception as e:
        print(f"âŒ CÃ¼mle bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ testi hatasÄ±: {e}")
        return False

def test_size_optimization():
    """200-800 karakter boyut optimizasyonu testi."""
    print("\nğŸ§ª BOYUT OPTÄ°MÄ°ZASYONU (200-800 KARAKTER)")
    print("=" * 50)
    
    try:
        chunks = create_semantic_chunks(
            TEST_TEXTS["academic_turkish"], 
            target_size=500, 
            language="tr"
        )
        
        size_stats = {
            'too_small': 0,  # <200 karakter
            'optimal': 0,    # 200-800 karakter
            'too_large': 0,  # >800 karakter
            'total_chunks': len(chunks)
        }
        
        for chunk in chunks:
            length = len(chunk)
            if length < 200:
                size_stats['too_small'] += 1
            elif length <= 800:
                size_stats['optimal'] += 1
            else:
                size_stats['too_large'] += 1
        
        optimal_ratio = size_stats['optimal'] / size_stats['total_chunks']
        
        print(f"âœ… Boyut optimizasyonu testi tamamlandÄ±:")
        print(f"   - Toplam chunk: {size_stats['total_chunks']}")
        print(f"   - Ã‡ok kÃ¼Ã§Ã¼k (<200): {size_stats['too_small']}")
        print(f"   - Optimal (200-800): {size_stats['optimal']}")
        print(f"   - Ã‡ok bÃ¼yÃ¼k (>800): {size_stats['too_large']}")
        print(f"   - Optimal oran: {optimal_ratio:.2%}")
        
        # En az %70 optimal olmalÄ±
        return optimal_ratio >= 0.7
    except Exception as e:
        print(f"âŒ Boyut optimizasyon testi hatasÄ±: {e}")
        traceback.print_exc()
        return False

def test_quality_control():
    """Kalite kontrolÃ¼ sistemi testi."""
    print("\nğŸ§ª KALÄ°TE KONTROLÃœ SÄ°STEMÄ°")
    print("=" * 50)
    
    chunker = SemanticChunker()
    
    try:
        # Test chunk'larÄ± oluÅŸtur
        test_chunks = [
            "Bu Ã§ok kÄ±sa.",  # KÃ¶tÃ¼ kalite - Ã§ok kÄ±sa
            "Bu iyi bir chunk Ã¶rneÄŸidir. Ä°Ã§inde birden fazla cÃ¼mle var. Boyutu da uygun aralÄ±kta. Kaliteli iÃ§eriÄŸe sahiptir.",  # Ä°yi kalite
            "Bu baÅŸlÄ±k var ama iÃ§erik yok\n# BaÅŸlÄ±k",  # KÃ¶tÃ¼ kalite - sadece baÅŸlÄ±k
            "Bu chunk Ã§ok uzun" + " uzun kelime" * 50,  # KÃ¶tÃ¼ kalite - Ã§ok uzun
        ]
        
        quality_results = []
        for i, chunk in enumerate(test_chunks):
            quality = chunker._validate_chunk_quality(chunk)
            quality_results.append(quality)
            
            status = "âœ… Ä°yi" if quality['is_valid'] else "âŒ KÃ¶tÃ¼"
            print(f"   Chunk {i+1}: {status} (Boyut: {len(chunk)}, Skor: {quality.get('size_score', 0):.2f})")
            if quality['issues']:
                print(f"      Sorunlar: {quality['issues']}")
        
        # En az 1 iyi, 1 kÃ¶tÃ¼ kalite olmalÄ±
        good_count = sum(1 for q in quality_results if q['is_valid'])
        bad_count = len(quality_results) - good_count
        
        print(f"âœ… Kalite kontrolÃ¼ testi: {good_count} iyi, {bad_count} kÃ¶tÃ¼ kalite tespit edildi")
        return True
    except Exception as e:
        print(f"âŒ Kalite kontrolÃ¼ testi hatasÄ±: {e}")
        traceback.print_exc()
        return False

def test_turkish_language_support():
    """TÃ¼rkÃ§e dil desteÄŸi testi."""
    print("\nğŸ§ª TÃœRKÃ‡E DÄ°L DESTEÄÄ°")
    print("=" * 50)
    
    try:
        # TÃ¼rkÃ§e karakterler ve noktalama
        turkish_text = """TÃ¼rkÃ§e dilinde Ã¶zel karakterler vardÄ±r: Ã§, ÄŸ, Ä±, Ã¶, ÅŸ, Ã¼. 
        Bu karakterler doÄŸru iÅŸlenmelidir. AyrÄ±ca TÃ¼rkÃ§e noktalama kurallarÄ± da Ã¶nemlidir.
        
        CÃ¼mleler dÃ¼zgÃ¼n kesilmelidir. TÃ¼rkÃ§e'de cÃ¼mle yapÄ±sÄ± Ä°ngilizce'den farklÄ±dÄ±r.
        Kelime sÄ±rasÄ± daha esnektir."""
        
        chunks = create_semantic_chunks(turkish_text, target_size=200, language="tr")
        
        print(f"âœ… TÃ¼rkÃ§e metin iÅŸleme baÅŸarÄ±lÄ±: {len(chunks)} chunk")
        
        # TÃ¼rkÃ§e karakterlerin korunduÄŸunu kontrol et
        turkish_chars = ['Ã§', 'ÄŸ', 'Ä±', 'Ã¶', 'ÅŸ', 'Ã¼', 'Ã‡', 'Ä', 'I', 'Ä°', 'Ã–', 'Å', 'Ãœ']
        all_chunks_text = ' '.join(chunks)
        
        preserved_chars = [char for char in turkish_chars if char in all_chunks_text]
        print(f"   Korunan TÃ¼rkÃ§e karakterler: {preserved_chars}")
        
        return len(preserved_chars) > 0
    except Exception as e:
        print(f"âŒ TÃ¼rkÃ§e dil desteÄŸi testi hatasÄ±: {e}")
        traceback.print_exc()
        return False

def test_performance():
    """Performans testi."""
    print("\nğŸ§ª PERFORMANS TESTÄ°")
    print("=" * 50)
    
    try:
        # BÃ¼yÃ¼k metin ile test
        large_text = TEST_TEXTS["academic_turkish"] * 5  # 5 kez Ã§oÄŸalt
        
        start_time = time.time()
        chunks = create_semantic_chunks(large_text, target_size=400, language="tr")
        end_time = time.time()
        
        processing_time = end_time - start_time
        chars_per_second = len(large_text) / processing_time if processing_time > 0 else 0
        
        print(f"âœ… Performans testi tamamlandÄ±:")
        print(f"   - Metin uzunluÄŸu: {len(large_text):,} karakter")
        print(f"   - Chunk sayÄ±sÄ±: {len(chunks)}")
        print(f"   - Ä°ÅŸlem sÃ¼resi: {processing_time:.2f} saniye")
        print(f"   - HÄ±z: {chars_per_second:,.0f} karakter/saniye")
        
        # 10 saniyeden az sÃ¼rmeli (makul bir sÃ¼re)
        return processing_time < 10.0
    except Exception as e:
        print(f"âŒ Performans testi hatasÄ±: {e}")
        traceback.print_exc()
        return False

def test_error_handling():
    """Hata yÃ¶netimi testi."""
    print("\nğŸ§ª HATA YÃ–NETÄ°MÄ° TESTÄ°")
    print("=" * 50)
    
    test_cases = [
        ("", "BoÅŸ string"),
        ("   ", "Sadece boÅŸluk"),
        ("A", "Tek karakter"),
        ("A" * 10000, "Ã‡ok uzun metin"),
        ("ğŸ™‚ ğŸ˜Š ğŸ‘", "Emoji iÃ§erikli metin")
    ]
    
    passed = 0
    for test_input, description in test_cases:
        try:
            chunks = create_semantic_chunks(test_input, target_size=300, language="tr")
            print(f"   âœ… {description}: {len(chunks)} chunk oluÅŸturuldu")
            passed += 1
        except Exception as e:
            print(f"   âŒ {description}: Hata - {e}")
    
    print(f"âœ… Hata yÃ¶netimi testi: {passed}/{len(test_cases)} test geÃ§ti")
    return passed == len(test_cases)

def run_comprehensive_test():
    """KapsamlÄ± test suitesi."""
    print("ğŸš€ GELÄ°ÅMÄ°Å SEMANTÄ°K CHUNKING SÄ°STEMÄ° TESTLERÄ°")
    print("=" * 60)
    
    tests = [
        ("Temel Fonksiyonalite", test_basic_functionality),
        ("Markdown YapÄ± Tespiti", test_markdown_structure),
        ("CÃ¼mle BÃ¼tÃ¼nlÃ¼ÄŸÃ¼", test_sentence_integrity),
        ("Boyut Optimizasyonu", test_size_optimization),
        ("Kalite KontrolÃ¼", test_quality_control),
        ("TÃ¼rkÃ§e Dil DesteÄŸi", test_turkish_language_support),
        ("Performans", test_performance),
        ("Hata YÃ¶netimi", test_error_handling),
    ]
    
    passed_tests = 0
    failed_tests = []
    
    for test_name, test_func in tests:
        try:
            print(f"\nâ–¶ï¸  {test_name} testi baÅŸlatÄ±lÄ±yor...")
            result = test_func()
            if result:
                passed_tests += 1
                print(f"âœ… {test_name} testi BAÅARILI")
            else:
                failed_tests.append(test_name)
                print(f"âŒ {test_name} testi BAÅARISIZ")
        except Exception as e:
            failed_tests.append(test_name)
            print(f"âŒ {test_name} testi HATA: {e}")
    
    # SonuÃ§ raporu
    print("\n" + "=" * 60)
    print("ğŸ“Š TEST SONUÃ‡LARI")
    print("=" * 60)
    print(f"Toplam Test: {len(tests)}")
    print(f"BaÅŸarÄ±lÄ±: {passed_tests}")
    print(f"BaÅŸarÄ±sÄ±z: {len(failed_tests)}")
    print(f"BaÅŸarÄ± OranÄ±: {passed_tests/len(tests)*100:.1f}%")
    
    if failed_tests:
        print(f"\nBaÅŸarÄ±sÄ±z Testler:")
        for test in failed_tests:
            print(f"  - {test}")
    else:
        print("\nğŸ‰ TÃœM TESTLER BAÅARILI!")
    
    return passed_tests == len(tests)

def demo_semantic_chunking():
    """Semantic chunking demo."""
    print("\nğŸ¯ SEMANTÄ°K CHUNKING DEMO")
    print("=" * 50)
    
    # Demo metin
    demo_text = TEST_TEXTS["academic_turkish"]
    
    print("Demo metin iÅŸleniyor...")
    print(f"Metin uzunluÄŸu: {len(demo_text)} karakter")
    
    # Chunking iÅŸlemi
    chunks = create_semantic_chunks(demo_text, target_size=500, language="tr")
    
    print(f"\nğŸ“š OluÅŸturulan {len(chunks)} chunk:")
    print("-" * 50)
    
    for i, chunk in enumerate(chunks, 1):
        print(f"\nğŸ“„ CHUNK {i} ({len(chunk)} karakter):")
        print("-" * 30)
        
        # Ä°lk 200 karakteri gÃ¶ster
        preview = chunk[:200] + "..." if len(chunk) > 200 else chunk
        print(preview)
        
        # Chunk Ã¶zelliklerini analiz et
        chunker = SemanticChunker()
        quality = chunker._validate_chunk_quality(chunk)
        
        print(f"\nğŸ“Š Kalite Analizi:")
        print(f"   Boyut Skoru: {quality['size_score']:.2f}")
        print(f"   TutarlÄ±lÄ±k: {quality['coherence_score']:.2f}")
        print(f"   YapÄ± Skoru: {quality['structure_score']:.2f}")
        print(f"   GeÃ§erli: {'âœ…' if quality['is_valid'] else 'âŒ'}")
        
        if quality['issues']:
            print(f"   Sorunlar: {', '.join(quality['issues'])}")

if __name__ == "__main__":
    try:
        # Ana test suitesi
        success = run_comprehensive_test()
        
        # Demo gÃ¶sterimi
        demo_semantic_chunking()
        
        # Ã‡Ä±kÄ±ÅŸ kodu
        exit_code = 0 if success else 1
        print(f"\nğŸ Test sÃ¼reci tamamlandÄ± (Ã‡Ä±kÄ±ÅŸ kodu: {exit_code})")
        sys.exit(exit_code)
        
    except KeyboardInterrupt:
        print("\nâ›” Test sÃ¼reci kullanÄ±cÄ± tarafÄ±ndan durduruldu")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ Beklenmeyen hata: {e}")
        traceback.print_exc()
        sys.exit(1)